{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc015c2b",
   "metadata": {},
   "source": [
    "Below is an explanation of how the notebook evolved - from testing individual steps to combining everything into one main function that produces a GDP/Investment/Consumption forecast for a target quarter (e.g., 2008Q1) based on 7 data vintages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce6a51",
   "metadata": {},
   "source": [
    "## 1. Define necessary inputs\n",
    "\n",
    "Before building the final function, I first specified the inputs required for the forecasting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda9694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input for the function\n",
    "\n",
    "# Target forecast quarter\n",
    "forecast_month = '2008-03' # 2008Q1\n",
    "# Quarterly variable being forecasted\n",
    "q_var = 'GDP'\n",
    "\n",
    "# Factor options:\n",
    "# 1. Specify whether group-specific factors are included\n",
    "aditional_factors = None # Use only the global factor\n",
    "# 2. Number of factors from each group\n",
    "factor_multiplicities = {'Global': 1} # Only one global factor\n",
    "# 3. Specify the lag order of the (vector) autoregressions that govern the dynamics of the factors\n",
    "factor_orders = {'Global': 3} # Global factor follows univariate AR(3) process \n",
    "# Start of the estimation sample\n",
    "start = '1991-04'\n",
    "\n",
    "# Text options:\n",
    "text_type = \"topics\"           # Type of text variables (e.g., \"topics\", \"topics_BPW\", \"topics_uncertainty\")\n",
    "estimation_period = \"2007\"     # Period marker (e.g., \"2007\" or \"2018\") indicating estimation sample for topics\n",
    "num_topics = \"200\"             # Number of topics in the LDA model (e.g., \"200\" or \"100\")\n",
    "source = \"all\"                 # \"all\", \"dpa\", \"hb\", \"sz\", or \"welt\"\n",
    "with_text = True               # If True, forecast with text variables; if False, forecast without\n",
    "only_text = True               # If True, forecast only with text variables; if False, use all Hard+Surveys+Text variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f168e47",
   "metadata": {},
   "source": [
    "## 2. Test the forecasting process for one specific quarter\n",
    "\n",
    "Before generalizing the code into a function that works for any quarter, I first tested the entire process for one specific quarter (2008Q1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171e2f1",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8873ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform(column, transforms):\n",
    "    transformation = transforms[column.name]\n",
    "    # For quarterly data like GDP, I will compute\n",
    "    # annualized percent changes\n",
    "    mult = 4 if column.index.freqstr[0] == 'Q' else 1\n",
    "    \n",
    "    # 1 => No transformation\n",
    "    if transformation == 1:\n",
    "        pass\n",
    "    # 2 => First difference\n",
    "    elif transformation == 2:\n",
    "        column = column.diff()\n",
    "    # 3 => Log first difference, multiplied by 100\n",
    "    #      (i.e. approximate percent change)\n",
    "    #      with optional multiplier for annualization\n",
    "    elif transformation == 3:\n",
    "        column = np.log(column).diff() * 100 * mult\n",
    "        \n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40117e37",
   "metadata": {},
   "source": [
    "### Load vintage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2ffc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(vintage, q_var):\n",
    "    \n",
    "    # - Monthly data --------------------------------------------------------------\n",
    "    # 1. Download data\n",
    "    orig_m = (pd.read_csv(f'../data/vintages_monthly/{vintage}.csv')\n",
    "                .dropna(how='all'))\n",
    "    \n",
    "    # 2. Extract transformation information\n",
    "    transform_m = orig_m.iloc[0, 1:]\n",
    "    orig_m = orig_m.iloc[1:]\n",
    "\n",
    "    # 3. Extract the date as an index\n",
    "    orig_m.index = pd.PeriodIndex(orig_m.date.tolist(), freq='M')\n",
    "    orig_m.drop('date', axis=1, inplace=True)\n",
    "\n",
    "    # 4. Apply the transformations\n",
    "    dta_m = orig_m.apply(transform, axis=0,\n",
    "                         transforms=transform_m)\n",
    "\n",
    "    # - Quarterly data --------------------------------------------------------------\n",
    "    # 1. Download data\n",
    "    orig_q = (pd.read_csv(f'../data/vintages_quarterly/{vintage}.csv')\n",
    "                .dropna(how='all'))\n",
    "    # Keep the quarterly variable that will be forecasted\n",
    "    orig_q = orig_q[['date', q_var]]\n",
    "\n",
    "    # 2. Extract transformation information\n",
    "    transform_q = orig_q.iloc[0, 1:]\n",
    "    orig_q = orig_q.iloc[1:]\n",
    "\n",
    "    # 3. Extract the date as an index\n",
    "    orig_q.index = pd.PeriodIndex(orig_q.date.tolist(), freq='Q')\n",
    "    orig_q.drop('date', axis=1, inplace=True)\n",
    "\n",
    "    # 4. Apply the transformations\n",
    "    dta_q = orig_q.apply(transform, axis=0,\n",
    "                          transforms=transform_q)\n",
    "\n",
    "    # - Output datasets ------------------------------------------------------\n",
    "    return types.SimpleNamespace(\n",
    "        orig_m=orig_m, orig_q=orig_q,\n",
    "        dta_m=dta_m, transform_m=transform_m,\n",
    "        dta_q=dta_q, transform_q=transform_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a1855",
   "metadata": {},
   "source": [
    "### Generating vintage dates\n",
    "\n",
    "The `vintage_dates()` function creates a list of 7 vintage date strings based on the target forecast month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97acdd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def vintage_dates(target_month):\n",
    "    \"\"\"\n",
    "    Given a target month string in \"YYYY-MM\" format, this function returns a list of 7 vintage date strings.\n",
    "    \n",
    "    For example, if target_month is \"2008-03\", it returns:\n",
    "      ['2008-01-01', '2008-01-16', '2008-02-01', '2008-02-16', '2008-03-01', '2008-03-16', '2008-04-01']\n",
    "    \"\"\"\n",
    "    # Convert target_month to a date object representing the first day of that month\n",
    "    target_date = datetime.strptime(target_month + \"-01\", \"%Y-%m-%d\").date()\n",
    "    \n",
    "    # The sequence should start two months before the target month\n",
    "    start_month = target_date - relativedelta(months=2)\n",
    "    \n",
    "    vintages = []\n",
    "    current = start_month\n",
    "    # For each month from start_month to target_date (inclusive), add the 1st and 16th day of the month\n",
    "    for _ in range(3):  # there are three months in a quarter\n",
    "        first_day = current\n",
    "        mid_month = current.replace(day=16)\n",
    "        vintages.append(first_day.strftime(\"%Y-%m-%d\"))\n",
    "        vintages.append(mid_month.strftime(\"%Y-%m-%d\"))\n",
    "        current += relativedelta(months=1)\n",
    "        \n",
    "    # Append the first day of the month following the target month\n",
    "    next_month = target_date + relativedelta(months=1)\n",
    "    vintages.append(next_month.strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "    return vintages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc196fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2008-01-01',\n",
       " '2008-01-16',\n",
       " '2008-02-01',\n",
       " '2008-02-16',\n",
       " '2008-03-01',\n",
       " '2008-03-16',\n",
       " '2008-04-01']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test this helper function ##\n",
    "vintages = vintage_dates(forecast_month)\n",
    "vintages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e25b9",
   "metadata": {},
   "source": [
    "### Load, transform, and organize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53cbe09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConstrProd</th>\n",
       "      <th>IP</th>\n",
       "      <th>ConstrNO</th>\n",
       "      <th>INO</th>\n",
       "      <th>ConstrTurn</th>\n",
       "      <th>ITurn</th>\n",
       "      <th>RetTurn</th>\n",
       "      <th>CPI</th>\n",
       "      <th>CPIEN</th>\n",
       "      <th>PPI</th>\n",
       "      <th>...</th>\n",
       "      <th>CorpDebt</th>\n",
       "      <th>PublicDebt</th>\n",
       "      <th>ifoIndTradeClimate</th>\n",
       "      <th>ifoIndTradeCurrent</th>\n",
       "      <th>ifoIndTradeExp</th>\n",
       "      <th>GfKBCE</th>\n",
       "      <th>GfKIE</th>\n",
       "      <th>GfKWtB</th>\n",
       "      <th>GfKCCI</th>\n",
       "      <th>ESI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-02</th>\n",
       "      <td>-22.030935</td>\n",
       "      <td>-1.923136</td>\n",
       "      <td>1.114218</td>\n",
       "      <td>-2.912262</td>\n",
       "      <td>-9.087038</td>\n",
       "      <td>-1.834914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.249688</td>\n",
       "      <td>0.371978</td>\n",
       "      <td>0.106326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-03</th>\n",
       "      <td>14.671067</td>\n",
       "      <td>-0.215983</td>\n",
       "      <td>-1.301134</td>\n",
       "      <td>0.118134</td>\n",
       "      <td>5.836116</td>\n",
       "      <td>-0.495051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>-0.212766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-04</th>\n",
       "      <td>-1.023550</td>\n",
       "      <td>-0.542007</td>\n",
       "      <td>-2.942785</td>\n",
       "      <td>-1.307208</td>\n",
       "      <td>5.134932</td>\n",
       "      <td>-0.872280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497513</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.742709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-05</th>\n",
       "      <td>-1.138140</td>\n",
       "      <td>-1.423122</td>\n",
       "      <td>5.437140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089188</td>\n",
       "      <td>-0.125235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.247832</td>\n",
       "      <td>0.245399</td>\n",
       "      <td>0.105652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ConstrProd        IP  ConstrNO       INO  ConstrTurn     ITurn  \\\n",
       "1991-01         NaN       NaN       NaN       NaN         NaN       NaN   \n",
       "1991-02  -22.030935 -1.923136  1.114218 -2.912262   -9.087038 -1.834914   \n",
       "1991-03   14.671067 -0.215983 -1.301134  0.118134    5.836116 -0.495051   \n",
       "1991-04   -1.023550 -0.542007 -2.942785 -1.307208    5.134932 -0.872280   \n",
       "1991-05   -1.138140 -1.423122  5.437140  0.000000    0.089188 -0.125235   \n",
       "\n",
       "         RetTurn       CPI     CPIEN       PPI  ...  CorpDebt  PublicDebt  \\\n",
       "1991-01      NaN       NaN       NaN       NaN  ...       NaN         NaN   \n",
       "1991-02      NaN  0.249688  0.371978  0.106326  ...     -0.28        -0.5   \n",
       "1991-03      NaN  0.000000  0.370600 -0.212766  ...     -0.33        -0.1   \n",
       "1991-04      NaN  0.497513  0.369231  0.742709  ...     -0.03         0.0   \n",
       "1991-05      NaN  0.247832  0.245399  0.105652  ...     -0.05         0.0   \n",
       "\n",
       "         ifoIndTradeClimate  ifoIndTradeCurrent  ifoIndTradeExp  GfKBCE  \\\n",
       "1991-01                 NaN                 NaN             NaN     NaN   \n",
       "1991-02                 0.3                 2.0            -1.3     NaN   \n",
       "1991-03                -2.9                -5.8            -0.3     NaN   \n",
       "1991-04                 0.1                -1.7             1.8     NaN   \n",
       "1991-05                -2.5                -5.1             0.0     NaN   \n",
       "\n",
       "         GfKIE  GfKWtB  GfKCCI  ESI  \n",
       "1991-01    NaN     NaN     NaN  NaN  \n",
       "1991-02    NaN     NaN     NaN -2.5  \n",
       "1991-03    NaN     NaN     NaN -3.9  \n",
       "1991-04    NaN     NaN     NaN  0.3  \n",
       "1991-05    NaN     NaN     NaN  0.1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the vintages of data\n",
    "dta = {date: load_data(date, q_var = q_var)\n",
    "       for date in vintages}\n",
    "dta['2008-01-01'].dta_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90e2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_data(vintage, q_var, text_type=\"topics\", estimation_period=\"2007\", num_topics=\"200\", source=\"all\"):\n",
    "    \n",
    "    # 1. Download data\n",
    "    filename = f'../data/vintages_monthly_{q_var}_{text_type}_{estimation_period}_{num_topics}_{source}/{vintage}.csv'\n",
    "    orig_text = pd.read_csv(filename).dropna(how='all')\n",
    "    \n",
    "    # 2. Extract transformation information\n",
    "    transform_text = orig_text.iloc[0, 1:]\n",
    "    orig_text = orig_text.iloc[1:]\n",
    "    \n",
    "    # 3. Extract the date as an index\n",
    "    orig_text.index = pd.PeriodIndex(orig_text.date.tolist(), freq='M')\n",
    "    orig_text.drop('date', axis=1, inplace=True)\n",
    "    \n",
    "    # 4. Apply the transformations\n",
    "    dta_text = orig_text.apply(transform, axis=0, transforms=transform_text)\n",
    "    \n",
    "     # - Output datasets \n",
    "    return types.SimpleNamespace(\n",
    "        orig_text=orig_text, \n",
    "        dta_text=dta_text, \n",
    "        transform_text=transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c8d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "if with_text:\n",
    "    # Loop over each vintage and load the corresponding text data\n",
    "    for date in vintages:\n",
    "        # Load text data for each vintage\n",
    "        text_obj = load_text_data(date, q_var=q_var, \n",
    "                                  text_type=text_type, \n",
    "                                  estimation_period=estimation_period, \n",
    "                                  num_topics=num_topics,\n",
    "                                  source=source)\n",
    "        if only_text:\n",
    "            dta[date].combined = text_obj.dta_text.copy()\n",
    "        else:\n",
    "            # Merge the monthly economic data (dta_m) with the text data\n",
    "            dta[date].combined = dta[date].dta_m.merge(text_obj.dta_text, left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23808f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the definitions Excel file for monthly variables\n",
    "defn_m = pd.read_excel('../data/data_monthly/variables_definitions.xlsx')\n",
    "# Set the index to the \"Mnemonic\" column\n",
    "defn_m.index = defn_m['Mnemonic']\n",
    "\n",
    "# Load the definitions Excel file for quarterly variables\n",
    "defn_q = pd.read_excel('../data/data_quarterly/variables_definitions.xlsx')\n",
    "defn_q = defn_q[defn_q.Mnemonic == q_var]\n",
    "defn_q.index = defn_q.Mnemonic\n",
    "\n",
    "if with_text:\n",
    "    # Load the definitions Excel file for text variables\n",
    "    defn_text = pd.read_excel(f'../data/data_text/variables_definitions_{q_var}_{text_type}_{estimation_period}_{num_topics}_{source}.xlsx')\n",
    "    defn_text.index = defn_text['Mnemonic']\n",
    "    \n",
    "    if only_text:\n",
    "        defn_combined = defn_text.copy()\n",
    "    else:\n",
    "        # Combine the definitions for monthly economic and text variables\n",
    "        defn_combined = pd.concat([defn_m, defn_text])\n",
    "\n",
    "# Replace the names of the columns in each monthly and quarterly dataset\n",
    "map_m = defn_m['Description'].to_dict()\n",
    "map_q = defn_q['Description'].to_dict()\n",
    "if with_text:\n",
    "    # When forecasting with text variables, also replace the names in the combined dataset\n",
    "    map_combined = defn_combined['Description'].to_dict()\n",
    "    \n",
    "for date, value in dta.items():\n",
    "    value.orig_m.columns = value.orig_m.columns.map(map_m)\n",
    "    value.dta_m.columns = value.dta_m.columns.map(map_m)\n",
    "    value.orig_q.columns = value.orig_q.columns.map(map_q)\n",
    "    value.dta_q.columns = value.dta_q.columns.map(map_q)\n",
    "    if with_text:\n",
    "        value.combined.columns = value.combined.columns.map(map_combined)\n",
    "    \n",
    "# Re-order the variables according to the definition file\n",
    "# (which is ordered by group)\n",
    "if with_text:\n",
    "    columns = [name for name in defn_combined['Description']\n",
    "           if name in dta[vintages[0]].combined.columns]\n",
    "    for date in dta.keys():\n",
    "        dta[date].combined = dta[date].combined.reindex(columns, axis=1)\n",
    "else:\n",
    "    columns = [name for name in defn_m['Description']\n",
    "               if name in dta[vintages[0]].dta_m.columns]\n",
    "    for date in dta.keys():\n",
    "        dta[date].dta_m = dta[date].dta_m.reindex(columns, axis=1)\n",
    "    \n",
    "# Get the mapping of variable mnemonic to group name, for monthly variables\n",
    "if with_text:\n",
    "    groups = defn_combined[['Description', 'Group']].copy()\n",
    "else:\n",
    "    groups = defn_m[['Description', 'Group']].copy()\n",
    "\n",
    "# Add our quarterly variable into the \"Activity\" group\n",
    "q_var_description = defn_q.loc[q_var, 'Description']\n",
    "groups.loc[q_var] = {'Description': q_var_description, 'Group': 'Activity'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f83937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crisis</th>\n",
       "      <th>Corporate Growth</th>\n",
       "      <th>Banking</th>\n",
       "      <th>Policy Measures</th>\n",
       "      <th>Problem Solving</th>\n",
       "      <th>US Politics</th>\n",
       "      <th>Commodity Markets</th>\n",
       "      <th>Economic Growth</th>\n",
       "      <th>Media Coverage of Plans and Rumors</th>\n",
       "      <th>Steel Industry Restructuring and Downsizing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991-04</th>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>-0.002345</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.001255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-05</th>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>-0.001558</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>-0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-06</th>\n",
       "      <td>-0.000803</td>\n",
       "      <td>-0.000279</td>\n",
       "      <td>-0.000439</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>-0.001147</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000372</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-07</th>\n",
       "      <td>-0.000615</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>-0.001791</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.000800</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>-0.000578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-08</th>\n",
       "      <td>-0.000858</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>-0.000955</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.000505</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>-0.002172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Crisis  Corporate Growth   Banking  Policy Measures  \\\n",
       "1991-04 -0.000184         -0.000235  0.000082         0.002874   \n",
       "1991-05 -0.000025          0.000014 -0.000108         0.001311   \n",
       "1991-06 -0.000803         -0.000279 -0.000439         0.000762   \n",
       "1991-07 -0.000615         -0.000241  0.000056         0.000796   \n",
       "1991-08 -0.000858         -0.000247  0.000883         0.000344   \n",
       "\n",
       "         Problem Solving  US Politics  Commodity Markets  Economic Growth  \\\n",
       "1991-04         0.002470    -0.002345           0.000179         0.000093   \n",
       "1991-05         0.001076    -0.001558           0.000183         0.000077   \n",
       "1991-06         0.000320    -0.001147          -0.000049        -0.000372   \n",
       "1991-07         0.000599    -0.001791          -0.000197        -0.000800   \n",
       "1991-08         0.000329    -0.000955          -0.000202        -0.000505   \n",
       "\n",
       "         Media Coverage of Plans and Rumors  \\\n",
       "1991-04                            0.000047   \n",
       "1991-05                            0.000231   \n",
       "1991-06                           -0.000087   \n",
       "1991-07                           -0.000535   \n",
       "1991-08                           -0.000154   \n",
       "\n",
       "         Steel Industry Restructuring and Downsizing  \n",
       "1991-04                                    -0.001255  \n",
       "1991-05                                    -0.001922  \n",
       "1991-06                                    -0.000711  \n",
       "1991-07                                    -0.000578  \n",
       "1991-08                                    -0.002172  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "if with_text:\n",
    "    display(dta['2008-01-01'].combined.head())\n",
    "else:\n",
    "    display(dta['2008-01-01'].dta_m.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6260b6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mnemonic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T50</th>\n",
       "      <td>Crisis</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T150</th>\n",
       "      <td>Corporate Growth</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T29</th>\n",
       "      <td>Banking</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T21</th>\n",
       "      <td>Policy Measures</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T38</th>\n",
       "      <td>Problem Solving</td>\n",
       "      <td>Text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Description Group\n",
       "Mnemonic                        \n",
       "T50                 Crisis  Text\n",
       "T150      Corporate Growth  Text\n",
       "T29                Banking  Text\n",
       "T21        Policy Measures  Text\n",
       "T38        Problem Solving  Text"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d26a71",
   "metadata": {},
   "source": [
    "### Defining the factor structure\n",
    "\n",
    "I use a helper function `factor_specification` that maps each variable (based on its description and group) to the factors that will load on it. This allows flexibility - for instance, using only a global factor, global plus group-specific factors, or separate factors for Hard+Surveys and Text data (the latter also loads on `q_var` growth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "639e64d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_specification(groups, additional_factors=None, q_var_description=None):\n",
    "    \"\"\"\n",
    "    Construct a dictionary mapping each variable\n",
    "    to a list of factors according to the desired specification.\n",
    "\n",
    "    Parameters:\n",
    "      groups : pandas.DataFrame\n",
    "          DataFrame that must contain at least two columns: \n",
    "          \"Description\" (the variable name) and \"Group\" (its group, e.g., 'Activity', 'Prices', 'Labor market',\n",
    "          'Financial', 'Surveys', or 'Text').\n",
    "      \n",
    "      additional_factors : None, str, or list of str\n",
    "          - If None or an empty list, only \"Global\" is included.\n",
    "          - If \"all\", then each variable loads on a global factor and a group-specific factor.\n",
    "          - If a list (e.g. ['Labor market'] or ['Prices', 'Labor market']), \n",
    "            then a variable gets the extra factor only if its group is in that list.\n",
    "          - If \"HardSurveys+Text\", then separate factors for Hard+Surveys and Text data (the latter also loads on q_var growth)\n",
    "          \n",
    "      q_var_description : str\n",
    "          The Description of the quarterly variable (e.g., 'Gross Domestic Product')\n",
    "            \n",
    "    Returns:\n",
    "      A dictionary where keys are the variable names and values are lists of factors.\n",
    "    \"\"\"\n",
    "    factors = {}\n",
    "    if additional_factors == \"HardSurveys+Text\":\n",
    "        for _, row in groups.iterrows():\n",
    "            desc = row['Description']\n",
    "            if desc == q_var_description:\n",
    "                # q_var loads on both factors\n",
    "                factors[desc] = ['HardSurveys', 'Text']\n",
    "            elif row['Group'] == 'Text':\n",
    "                factors[desc] = ['Text']\n",
    "            else:\n",
    "                factors[desc] = ['HardSurveys']\n",
    "                \n",
    "        return factors\n",
    "\n",
    "    for _, row in groups.iterrows():\n",
    "        desc = row['Description']\n",
    "        group = row['Group']\n",
    "        facs = ['Global']  # Always include the global factor\n",
    "\n",
    "        if additional_factors:\n",
    "            # If \"all\" then include each variable's own group as a factor.\n",
    "            if additional_factors == \"all\":\n",
    "                facs.append(group)\n",
    "            # If additional_factors is a list, only include if the group's name is in the list.\n",
    "            elif isinstance(additional_factors, list) and group in additional_factors:\n",
    "                facs.append(group)\n",
    "        factors[desc] = facs\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3dc9358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Crisis': ['Global'],\n",
       " 'Corporate Growth': ['Global'],\n",
       " 'Banking': ['Global'],\n",
       " 'Policy Measures': ['Global'],\n",
       " 'Problem Solving': ['Global'],\n",
       " 'US Politics': ['Global'],\n",
       " 'Commodity Markets': ['Global'],\n",
       " 'Economic Growth': ['Global'],\n",
       " 'Media Coverage of Plans and Rumors': ['Global'],\n",
       " 'Steel Industry Restructuring and Downsizing': ['Global'],\n",
       " 'Gross Domestic Product': ['Global']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors = factor_specification(groups, additional_factors = aditional_factors, q_var_description = q_var_description)\n",
    "factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda9502b",
   "metadata": {},
   "source": [
    "### Constructing the Dynamic Factor Model and Extracting Forecasts\n",
    "\n",
    "For each vintage, the model produces a point forecast for GDP/Consumption/Investment for the target quarter. I collect these forecasts into a dictionary for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb2749",
   "metadata": {},
   "source": [
    "#### First vintage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53fb6614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM start iterations, llf=-2404.3\n",
      "EM iteration 10, llf=-2353.5, convergence criterion=9.2478e-05\n",
      "EM iteration 20, llf=-2352.2, convergence criterion=3.5772e-05\n",
      "EM iteration 30, llf=-2351.6, convergence criterion=1.806e-05\n",
      "EM iteration 40, llf=-2351.3, convergence criterion=1.0695e-05\n",
      "EM iteration 50, llf=-2351.1, convergence criterion=7.133e-06\n",
      "EM iteration 60, llf=-2351, convergence criterion=5.152e-06\n",
      "EM iteration 70, llf=-2350.9, convergence criterion=3.9323e-06\n",
      "EM iteration 80, llf=-2350.8, convergence criterion=3.1216e-06\n",
      "EM iteration 90, llf=-2350.7, convergence criterion=2.5504e-06\n",
      "EM iteration 100, llf=-2350.7, convergence criterion=2.1297e-06\n",
      "EM iteration 110, llf=-2350.6, convergence criterion=1.8088e-06\n",
      "EM iteration 120, llf=-2350.6, convergence criterion=1.5573e-06\n",
      "EM iteration 130, llf=-2350.6, convergence criterion=1.3558e-06\n",
      "EM iteration 140, llf=-2350.5, convergence criterion=1.1914e-06\n",
      "EM iteration 150, llf=-2350.5, convergence criterion=1.0552e-06\n",
      "EM converged at iteration 155, llf=-2350.5, convergence criterion=9.9573e-07 < tolerance=1e-06\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Get monthly and quarterly datasets\n",
    "if with_text:\n",
    "    endog_m = dta[vintages[0]].combined.loc[start:, :]\n",
    "else:\n",
    "    endog_m = dta[vintages[0]].dta_m.loc[start:, :]\n",
    "endog_q = dta[vintages[0]].dta_q.loc[start:, [q_var_description]]\n",
    "\n",
    "# Construct the dynamic factor model\n",
    "model = sm.tsa.DynamicFactorMQ(\n",
    "    endog_m, endog_quarterly=endog_q,\n",
    "    factors=factors, factor_orders=factor_orders,\n",
    "    factor_multiplicities=factor_multiplicities)\n",
    "\n",
    "results = model.fit(disp=10)\n",
    "\n",
    "# The point forecast for the quarter of interest\n",
    "point_forecast = results.get_prediction(start = forecast_month, end = forecast_month).predicted_mean[q_var_description]\n",
    "\n",
    "forecast_value = point_forecast.loc[forecast_month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13d7046c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.362276153737156)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b01c3cb",
   "metadata": {},
   "source": [
    "#### All vintages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9d4ecf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM start iterations, llf=-2404.3\n",
      "EM iteration 10, llf=-2353.5, convergence criterion=9.2478e-05\n",
      "EM iteration 20, llf=-2352.2, convergence criterion=3.5772e-05\n",
      "EM iteration 30, llf=-2351.6, convergence criterion=1.806e-05\n",
      "EM iteration 40, llf=-2351.3, convergence criterion=1.0695e-05\n",
      "EM iteration 50, llf=-2351.1, convergence criterion=7.133e-06\n",
      "EM iteration 60, llf=-2351, convergence criterion=5.152e-06\n",
      "EM iteration 70, llf=-2350.9, convergence criterion=3.9323e-06\n",
      "EM iteration 80, llf=-2350.8, convergence criterion=3.1216e-06\n",
      "EM iteration 90, llf=-2350.7, convergence criterion=2.5504e-06\n",
      "EM iteration 100, llf=-2350.7, convergence criterion=2.1297e-06\n",
      "EM iteration 110, llf=-2350.6, convergence criterion=1.8088e-06\n",
      "EM iteration 120, llf=-2350.6, convergence criterion=1.5573e-06\n",
      "EM iteration 130, llf=-2350.6, convergence criterion=1.3558e-06\n",
      "EM iteration 140, llf=-2350.5, convergence criterion=1.1914e-06\n",
      "EM iteration 150, llf=-2350.5, convergence criterion=1.0552e-06\n",
      "EM converged at iteration 155, llf=-2350.5, convergence criterion=9.9573e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-2404.3\n",
      "EM iteration 10, llf=-2353.5, convergence criterion=9.2478e-05\n",
      "EM iteration 20, llf=-2352.2, convergence criterion=3.5772e-05\n",
      "EM iteration 30, llf=-2351.6, convergence criterion=1.806e-05\n",
      "EM iteration 40, llf=-2351.3, convergence criterion=1.0695e-05\n",
      "EM iteration 50, llf=-2351.1, convergence criterion=7.133e-06\n",
      "EM iteration 60, llf=-2351, convergence criterion=5.152e-06\n",
      "EM iteration 70, llf=-2350.9, convergence criterion=3.9323e-06\n",
      "EM iteration 80, llf=-2350.8, convergence criterion=3.1216e-06\n",
      "EM iteration 90, llf=-2350.7, convergence criterion=2.5504e-06\n",
      "EM iteration 100, llf=-2350.7, convergence criterion=2.1297e-06\n",
      "EM iteration 110, llf=-2350.6, convergence criterion=1.8088e-06\n",
      "EM iteration 120, llf=-2350.6, convergence criterion=1.5573e-06\n",
      "EM iteration 130, llf=-2350.6, convergence criterion=1.3558e-06\n",
      "EM iteration 140, llf=-2350.5, convergence criterion=1.1914e-06\n",
      "EM iteration 150, llf=-2350.5, convergence criterion=1.0552e-06\n",
      "EM converged at iteration 155, llf=-2350.5, convergence criterion=9.9573e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-2417.1\n",
      "EM iteration 10, llf=-2366.1, convergence criterion=9.0483e-05\n",
      "EM iteration 20, llf=-2364.9, convergence criterion=3.5133e-05\n",
      "EM iteration 30, llf=-2364.3, convergence criterion=1.7831e-05\n",
      "EM iteration 40, llf=-2364, convergence criterion=1.0606e-05\n",
      "EM iteration 50, llf=-2363.8, convergence criterion=7.1011e-06\n",
      "EM iteration 60, llf=-2363.6, convergence criterion=5.1448e-06\n",
      "EM iteration 70, llf=-2363.5, convergence criterion=3.9355e-06\n",
      "EM iteration 80, llf=-2363.5, convergence criterion=3.1286e-06\n",
      "EM iteration 90, llf=-2363.4, convergence criterion=2.5582e-06\n",
      "EM iteration 100, llf=-2363.3, convergence criterion=2.1368e-06\n",
      "EM iteration 110, llf=-2363.3, convergence criterion=1.8146e-06\n",
      "EM iteration 120, llf=-2363.3, convergence criterion=1.5617e-06\n",
      "EM iteration 130, llf=-2363.2, convergence criterion=1.3588e-06\n",
      "EM iteration 140, llf=-2363.2, convergence criterion=1.1932e-06\n",
      "EM iteration 150, llf=-2363.2, convergence criterion=1.056e-06\n",
      "EM converged at iteration 155, llf=-2363.2, convergence criterion=9.9609e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-2418.6\n",
      "EM iteration 10, llf=-2367.6, convergence criterion=9.1258e-05\n",
      "EM iteration 20, llf=-2366.3, convergence criterion=3.5141e-05\n",
      "EM iteration 30, llf=-2365.8, convergence criterion=1.7746e-05\n",
      "EM iteration 40, llf=-2365.4, convergence criterion=1.055e-05\n",
      "EM iteration 50, llf=-2365.2, convergence criterion=7.0597e-06\n",
      "EM iteration 60, llf=-2365.1, convergence criterion=5.112e-06\n",
      "EM iteration 70, llf=-2365, convergence criterion=3.9084e-06\n",
      "EM iteration 80, llf=-2364.9, convergence criterion=3.1054e-06\n",
      "EM iteration 90, llf=-2364.9, convergence criterion=2.5379e-06\n",
      "EM iteration 100, llf=-2364.8, convergence criterion=2.1188e-06\n",
      "EM iteration 110, llf=-2364.8, convergence criterion=1.7986e-06\n",
      "EM iteration 120, llf=-2364.7, convergence criterion=1.5472e-06\n",
      "EM iteration 130, llf=-2364.7, convergence criterion=1.3457e-06\n",
      "EM iteration 140, llf=-2364.7, convergence criterion=1.1813e-06\n",
      "EM iteration 150, llf=-2364.6, convergence criterion=1.0451e-06\n",
      "EM converged at iteration 154, llf=-2364.6, convergence criterion=9.9715e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-2434.7\n",
      "EM iteration 10, llf=-2383.5, convergence criterion=9.4099e-05\n",
      "EM iteration 20, llf=-2382.2, convergence criterion=3.5842e-05\n",
      "EM iteration 30, llf=-2381.6, convergence criterion=1.7925e-05\n",
      "EM iteration 40, llf=-2381.3, convergence criterion=1.0564e-05\n",
      "EM iteration 50, llf=-2381.1, convergence criterion=7.0196e-06\n",
      "EM iteration 60, llf=-2381, convergence criterion=5.0576e-06\n",
      "EM iteration 70, llf=-2380.9, convergence criterion=3.8543e-06\n",
      "EM iteration 80, llf=-2380.8, convergence criterion=3.0572e-06\n",
      "EM iteration 90, llf=-2380.7, convergence criterion=2.4971e-06\n",
      "EM iteration 100, llf=-2380.7, convergence criterion=2.0854e-06\n",
      "EM iteration 110, llf=-2380.6, convergence criterion=1.7718e-06\n",
      "EM iteration 120, llf=-2380.6, convergence criterion=1.5262e-06\n",
      "EM iteration 130, llf=-2380.5, convergence criterion=1.3294e-06\n",
      "EM iteration 140, llf=-2380.5, convergence criterion=1.1689e-06\n",
      "EM iteration 150, llf=-2380.5, convergence criterion=1.036e-06\n",
      "EM converged at iteration 154, llf=-2380.5, convergence criterion=9.8915e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-2434.7\n",
      "EM iteration 10, llf=-2383.5, convergence criterion=9.4099e-05\n",
      "EM iteration 20, llf=-2382.2, convergence criterion=3.5842e-05\n",
      "EM iteration 30, llf=-2381.6, convergence criterion=1.7925e-05\n",
      "EM iteration 40, llf=-2381.3, convergence criterion=1.0564e-05\n",
      "EM iteration 50, llf=-2381.1, convergence criterion=7.0196e-06\n",
      "EM iteration 60, llf=-2381, convergence criterion=5.0576e-06\n",
      "EM iteration 70, llf=-2380.9, convergence criterion=3.8543e-06\n",
      "EM iteration 80, llf=-2380.8, convergence criterion=3.0572e-06\n",
      "EM iteration 90, llf=-2380.7, convergence criterion=2.4971e-06\n",
      "EM iteration 100, llf=-2380.7, convergence criterion=2.0854e-06\n",
      "EM iteration 110, llf=-2380.6, convergence criterion=1.7718e-06\n",
      "EM iteration 120, llf=-2380.6, convergence criterion=1.5262e-06\n",
      "EM iteration 130, llf=-2380.5, convergence criterion=1.3294e-06\n",
      "EM iteration 140, llf=-2380.5, convergence criterion=1.1689e-06\n",
      "EM iteration 150, llf=-2380.5, convergence criterion=1.036e-06\n",
      "EM converged at iteration 154, llf=-2380.5, convergence criterion=9.8915e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-2446.9\n",
      "EM iteration 10, llf=-2395.7, convergence criterion=8.7239e-05\n",
      "EM iteration 20, llf=-2394.4, convergence criterion=3.3826e-05\n",
      "EM iteration 30, llf=-2393.9, convergence criterion=1.7259e-05\n",
      "EM iteration 40, llf=-2393.6, convergence criterion=1.0343e-05\n",
      "EM iteration 50, llf=-2393.4, convergence criterion=6.9648e-06\n",
      "EM iteration 60, llf=-2393.2, convergence criterion=5.0637e-06\n",
      "EM iteration 70, llf=-2393.1, convergence criterion=3.8786e-06\n",
      "EM iteration 80, llf=-2393, convergence criterion=3.0818e-06\n",
      "EM iteration 90, llf=-2393, convergence criterion=2.5152e-06\n",
      "EM iteration 100, llf=-2392.9, convergence criterion=2.0951e-06\n",
      "EM iteration 110, llf=-2392.9, convergence criterion=1.7734e-06\n",
      "EM iteration 120, llf=-2392.8, convergence criterion=1.5209e-06\n",
      "EM iteration 130, llf=-2392.8, convergence criterion=1.3187e-06\n",
      "EM iteration 140, llf=-2392.8, convergence criterion=1.1541e-06\n",
      "EM iteration 150, llf=-2392.7, convergence criterion=1.0182e-06\n",
      "EM converged at iteration 152, llf=-2392.7, convergence criterion=9.9392e-07 < tolerance=1e-06\n"
     ]
    }
   ],
   "source": [
    "# Prepare an empty dictionary to store forecast values based on each vintage\n",
    "forecasts = {}\n",
    "\n",
    "for vint in vintages:\n",
    "    # Get monthly and quarterly datasets for this vintage\n",
    "    if with_text:\n",
    "        endog_m = dta[vint].combined.loc[start:, :]\n",
    "    else:\n",
    "        endog_m = dta[vint].dta_m.loc[start:, :]\n",
    "    endog_q = dta[vint].dta_q.loc[start:, [q_var_description]]\n",
    "    \n",
    "    # Construct the dynamic factor model\n",
    "    model = sm.tsa.DynamicFactorMQ(\n",
    "        endog_m, endog_quarterly=endog_q,\n",
    "        factors=factors, factor_orders=factor_orders,\n",
    "        factor_multiplicities=factor_multiplicities)\n",
    "    \n",
    "    # Fit the model\n",
    "    results = model.fit(disp=10)\n",
    "    \n",
    "    # Get the point forecast for the quarter of interest\n",
    "    point_forecast = results.get_prediction(start=forecast_month, end=forecast_month).predicted_mean[q_var_description]\n",
    "    \n",
    "    # Extract the forecast value using the forecast_date index\n",
    "    forecast_value = point_forecast.loc[forecast_month]\n",
    "    \n",
    "    # Save the forecast value associated with the vintage\n",
    "    forecasts[vint] = forecast_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b0f4b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2008-01-01': np.float64(2.362276153737156),\n",
       " '2008-01-16': np.float64(2.362276153737156),\n",
       " '2008-02-01': np.float64(1.8512675006274713),\n",
       " '2008-02-16': np.float64(1.8158190369680773),\n",
       " '2008-03-01': np.float64(1.6498734299580078),\n",
       " '2008-03-16': np.float64(1.6498734299580078),\n",
       " '2008-04-01': np.float64(1.6668235845101256)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5b93e",
   "metadata": {},
   "source": [
    "## 3. Combining everything into the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a72a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "# --- Helper functions ---\n",
    "\n",
    "def transform(column, transforms):\n",
    "    transformation = transforms[column.name]\n",
    "    # For quarterly data like GDP, I will compute\n",
    "    # annualized percent changes\n",
    "    mult = 4 if column.index.freqstr[0] == 'Q' else 1\n",
    "    \n",
    "    # 1 => No transformation\n",
    "    if transformation == 1:\n",
    "        pass\n",
    "    # 2 => First difference\n",
    "    elif transformation == 2:\n",
    "        column = column.diff()\n",
    "    # 3 => Log first difference, multiplied by 100\n",
    "    #      (i.e. approximate percent change)\n",
    "    #      with optional multiplier for annualization\n",
    "    elif transformation == 3:\n",
    "        column = np.log(column).diff() * 100 * mult\n",
    "        \n",
    "    return column\n",
    "\n",
    "def load_data(vintage, q_var):\n",
    "    \n",
    "    # - Monthly data --------------------------------------------------------------\n",
    "    # 1. Download data\n",
    "    orig_m = (pd.read_csv(f'../data/vintages_monthly/{vintage}.csv')\n",
    "                .dropna(how='all'))\n",
    "    \n",
    "    # 2. Extract transformation information\n",
    "    transform_m = orig_m.iloc[0, 1:]\n",
    "    orig_m = orig_m.iloc[1:]\n",
    "\n",
    "    # 3. Extract the date as an index\n",
    "    orig_m.index = pd.PeriodIndex(orig_m.date.tolist(), freq='M')\n",
    "    orig_m.drop('date', axis=1, inplace=True)\n",
    "\n",
    "    # 4. Apply the transformations\n",
    "    dta_m = orig_m.apply(transform, axis=0,\n",
    "                         transforms=transform_m)\n",
    "\n",
    "    # - Quarterly data --------------------------------------------------------------\n",
    "    # 1. Download data\n",
    "    orig_q = (pd.read_csv(f'../data/vintages_quarterly/{vintage}.csv')\n",
    "                .dropna(how='all'))\n",
    "    # Keep the quarterly variable that will be forecasted\n",
    "    orig_q = orig_q[['date', q_var]]\n",
    "\n",
    "    # 2. Extract transformation information\n",
    "    transform_q = orig_q.iloc[0, 1:]\n",
    "    orig_q = orig_q.iloc[1:]\n",
    "\n",
    "    # 3. Extract the date as an index\n",
    "    orig_q.index = pd.PeriodIndex(orig_q.date.tolist(), freq='Q')\n",
    "    orig_q.drop('date', axis=1, inplace=True)\n",
    "\n",
    "    # 4. Apply the transformations\n",
    "    dta_q = orig_q.apply(transform, axis=0,\n",
    "                          transforms=transform_q)\n",
    "\n",
    "    # - Output datasets ------------------------------------------------------\n",
    "    return types.SimpleNamespace(\n",
    "        orig_m=orig_m, orig_q=orig_q,\n",
    "        dta_m=dta_m, transform_m=transform_m,\n",
    "        dta_q=dta_q, transform_q=transform_q)\n",
    "\n",
    "def vintage_dates(target_month):\n",
    "    \"\"\"\n",
    "    Given a target month string in \"YYYY-MM\" format, this function returns a list of 7 vintage date strings.\n",
    "    \n",
    "    For example, if target_month is \"2008-03\", it returns:\n",
    "      ['2008-01-01', '2008-01-16', '2008-02-01', '2008-02-16', '2008-03-01', '2008-03-16', '2008-04-01']\n",
    "    \"\"\"\n",
    "    # Convert target_month to a date object representing the first day of that month\n",
    "    target_date = datetime.strptime(target_month + \"-01\", \"%Y-%m-%d\").date()\n",
    "    \n",
    "    # The sequence should start two months before the target month\n",
    "    start_month = target_date - relativedelta(months=2)\n",
    "    \n",
    "    vintages = []\n",
    "    current = start_month\n",
    "    # For each month from start_month to target_date (inclusive), add the 1st and 16th day of the month\n",
    "    for _ in range(3):  # there are three months in a quarter\n",
    "        first_day = current\n",
    "        mid_month = current.replace(day=16)\n",
    "        vintages.append(first_day.strftime(\"%Y-%m-%d\"))\n",
    "        vintages.append(mid_month.strftime(\"%Y-%m-%d\"))\n",
    "        current += relativedelta(months=1)\n",
    "        \n",
    "    # Append the first day of the month following the target month\n",
    "    next_month = target_date + relativedelta(months=1)\n",
    "    vintages.append(next_month.strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "    return vintages\n",
    "\n",
    "def load_text_data(vintage, q_var, text_type=\"topics\", estimation_period=\"2007\", num_topics=\"200\", source=\"all\"):\n",
    "    \n",
    "    # 1. Download data\n",
    "    filename = f'../data/vintages_monthly_{q_var}_{text_type}_{estimation_period}_{num_topics}_{source}/{vintage}.csv'\n",
    "    orig_text = pd.read_csv(filename).dropna(how='all')\n",
    "    \n",
    "    # 2. Extract transformation information\n",
    "    transform_text = orig_text.iloc[0, 1:]\n",
    "    orig_text = orig_text.iloc[1:]\n",
    "    \n",
    "    # 3. Extract the date as an index\n",
    "    orig_text.index = pd.PeriodIndex(orig_text.date.tolist(), freq='M')\n",
    "    orig_text.drop('date', axis=1, inplace=True)\n",
    "    \n",
    "    # 4. Apply the transformations\n",
    "    dta_text = orig_text.apply(transform, axis=0, transforms=transform_text)\n",
    "    \n",
    "     # - Output datasets \n",
    "    return types.SimpleNamespace(\n",
    "        orig_text=orig_text, \n",
    "        dta_text=dta_text, \n",
    "        transform_text=transform_text)\n",
    "\n",
    "def factor_specification(groups, additional_factors=None, q_var_description=None):\n",
    "    \"\"\"\n",
    "    Construct a dictionary mapping each variable\n",
    "    to a list of factors according to the desired specification.\n",
    "\n",
    "    Parameters:\n",
    "      groups : pandas.DataFrame\n",
    "          DataFrame that must contain at least two columns: \n",
    "          \"Description\" (the variable name) and \"Group\" (its group, e.g., 'Activity', 'Prices', 'Labor market',\n",
    "          'Financial', 'Surveys', or 'Text').\n",
    "      \n",
    "      additional_factors : None, str, or list of str\n",
    "          - If None or an empty list, only \"Global\" is included.\n",
    "          - If \"all\", then each variable loads on a global factor and a group-specific factor.\n",
    "          - If a list (e.g. ['Labor market'] or ['Prices', 'Labor market']), \n",
    "            then a variable gets the extra factor only if its group is in that list.\n",
    "          - If \"HardSurveys+Text\", then separate factors for Hard+Surveys and Text data (the latter also loads on q_var growth)\n",
    "          \n",
    "      q_var_description : str\n",
    "          The Description of the quarterly variable (e.g., 'Gross Domestic Product')\n",
    "            \n",
    "    Returns:\n",
    "      A dictionary where keys are the variable names and values are lists of factors.\n",
    "    \"\"\"\n",
    "    factors = {}\n",
    "    if additional_factors == \"HardSurveys+Text\":\n",
    "        for _, row in groups.iterrows():\n",
    "            desc = row['Description']\n",
    "            if desc == q_var_description:\n",
    "                # q_var loads on both factors\n",
    "                factors[desc] = ['HardSurveys', 'Text']\n",
    "            elif row['Group'] == 'Text':\n",
    "                factors[desc] = ['Text']\n",
    "            else:\n",
    "                factors[desc] = ['HardSurveys']\n",
    "                \n",
    "        return factors\n",
    "\n",
    "    for _, row in groups.iterrows():\n",
    "        desc = row['Description']\n",
    "        group = row['Group']\n",
    "        facs = ['Global']  # Always include the global factor\n",
    "\n",
    "        if additional_factors:\n",
    "            # If \"all\" then include each variable's own group as a factor.\n",
    "            if additional_factors == \"all\":\n",
    "                facs.append(group)\n",
    "            # If additional_factors is a list, only include if the group's name is in the list.\n",
    "            elif isinstance(additional_factors, list) and group in additional_factors:\n",
    "                facs.append(group)\n",
    "        factors[desc] = facs\n",
    "    return factors\n",
    "\n",
    "# --- Main function that produces forecasts for the quarter of interest based on 7 vintages ---\n",
    "def get_forecasts(forecast_month, q_var, additional_factors, factor_multiplicities, factor_orders, start, text_type=\"topics\",\n",
    "                 estimation_period=\"2007\", num_topics=\"200\", source=\"all\", with_text=False, only_text=False):\n",
    "    \"\"\"\n",
    "    Given the input parameters, this function:\n",
    "      - Generates the list of vintage dates for the forecast month.\n",
    "      - Loads monthly and quarterly datasets for each vintage.\n",
    "      - Loads variable definition files, renames variables in the original dataset and reorders them.\n",
    "      - Specifies the factor structure based on additional_factors.\n",
    "      - Constructs and fits a monthly Dynamic Factor Model for each vintage.\n",
    "      - Returns a dictionary of forecast values (keyed by vintage) for GDP/Consumption/Investment.\n",
    "    \n",
    "    Parameters:\n",
    "      forecast_month: string in \"YYYY-MM\" format (e.g., \"2008-03\")\n",
    "      q_var: string, quarterly variable being forecasted (e.g., 'GDP')\n",
    "      additional_factors: None, \"all\", a list of groups (e.g., ['Labor market']), or 'HardSurveys+Text'\n",
    "      factor_multiplicities: dictionary (e.g., {'Global': 1})\n",
    "      factor_orders: dictionary (e.g., {'Global': 3})\n",
    "      start: string indicating start date for estimation sample (e.g., \"1991-02\")\n",
    "      text_type: Type of text variables (e.g., \"topics\", \"topics_BPW\", \"topics_uncertainty\")\n",
    "      estimation_period: Period marker (e.g., \"2007\" or \"2018\") indicating estimation sample for topics\n",
    "      num_topics: Number of topics in the model (e.g., \"200\" or \"100\")\n",
    "      source: \"all\", \"dpa\", \"hb\", \"sz\", or \"welt\"\n",
    "      with_text: If True, forecast with text variables; if False, forecast without\n",
    "      only_text: If True, forecast only with text variables; if False, use all the Hard+Surveys+Text variables\n",
    "    \n",
    "    Returns:\n",
    "      forecasts: dict mapping vintage date (string) to forecast value (for GDP/Consumption/Investment)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate vintage dates\n",
    "    vintages = vintage_dates(forecast_month)\n",
    "    \n",
    "    # Load data for each vintage\n",
    "    dta = {vint: load_data(vint, q_var = q_var) for vint in vintages}\n",
    "    \n",
    "    if with_text:\n",
    "        # Loop over each vintage and load the corresponding text data\n",
    "        for vint in vintages:\n",
    "            # Load text data for each vintage\n",
    "            text_obj = load_text_data(vint, q_var=q_var, \n",
    "                                      text_type=text_type, \n",
    "                                      estimation_period=estimation_period, \n",
    "                                      num_topics=num_topics,\n",
    "                                      source=source)\n",
    "            \n",
    "            if only_text:\n",
    "                dta[vint].combined = text_obj.dta_text.copy()\n",
    "            else:\n",
    "                # Merge the monthly economic data (dta_m) with the text data\n",
    "                dta[vint].combined = dta[vint].dta_m.merge(text_obj.dta_text, left_index=True, right_index=True, how='outer')\n",
    "    \n",
    "    # Load definitions for monthly and quarterly variables\n",
    "    defn_m = pd.read_excel('../data/data_monthly/variables_definitions.xlsx')\n",
    "    defn_m.index = defn_m['Mnemonic']\n",
    "    defn_q = pd.read_excel('../data/data_quarterly/variables_definitions.xlsx')\n",
    "    defn_q = defn_q[defn_q.Mnemonic == q_var]\n",
    "    defn_q.index = defn_q['Mnemonic']\n",
    "    if with_text:\n",
    "        # Load the definitions Excel file for text variables\n",
    "        defn_text = pd.read_excel(f'../data/data_text/variables_definitions_{q_var}_{text_type}_{estimation_period}_{num_topics}_{source}.xlsx')\n",
    "        defn_text.index = defn_text['Mnemonic']\n",
    "        \n",
    "        if only_text:\n",
    "            defn_combined = defn_text.copy()\n",
    "        else:\n",
    "            # Combine the definitions for monthly economic and text variables\n",
    "            defn_combined = pd.concat([defn_m, defn_text])\n",
    "         \n",
    "    # Create mapping from mnemonic to description\n",
    "    map_m = defn_m['Description'].to_dict()\n",
    "    map_q = defn_q['Description'].to_dict()\n",
    "    if with_text:\n",
    "        # When forecasting with text variables, also replace the names in the combined dataset\n",
    "        map_combined = defn_combined['Description'].to_dict()\n",
    "    \n",
    "    # Replace column names for monthly and quarterly datasets in each vintage\n",
    "    for vint in dta.keys():\n",
    "        dta[vint].orig_m.columns = dta[vint].orig_m.columns.map(map_m)\n",
    "        dta[vint].dta_m.columns = dta[vint].dta_m.columns.map(map_m)\n",
    "        dta[vint].orig_q.columns = dta[vint].orig_q.columns.map(map_q)\n",
    "        dta[vint].dta_q.columns = dta[vint].dta_q.columns.map(map_q)\n",
    "        if with_text:\n",
    "            dta[vint].combined.columns = dta[vint].combined.columns.map(map_combined)\n",
    "    \n",
    "    # Re-order the monthly data columns based on the definitions file order\n",
    "    if with_text:\n",
    "        columns = [name for name in defn_combined['Description']\n",
    "               if name in dta[vintages[0]].combined.columns]\n",
    "        for vint in dta.keys():\n",
    "            dta[vint].combined = dta[vint].combined.reindex(columns, axis=1)\n",
    "    else:\n",
    "        columns = [name for name in defn_m['Description']\n",
    "                   if name in dta[vintages[0]].dta_m.columns]\n",
    "        for vint in dta.keys():\n",
    "            dta[vint].dta_m = dta[vint].dta_m.reindex(columns, axis=1)\n",
    "        \n",
    "    # Get groups (variable -> group) mapping from monthly definitions\n",
    "    if with_text:\n",
    "        groups = defn_combined[['Description', 'Group']].copy()\n",
    "    else:\n",
    "        groups = defn_m[['Description', 'Group']].copy()\n",
    "    \n",
    "    # Add our quarterly variable into the \"Activity\" group\n",
    "    q_var_description = defn_q.loc[q_var, 'Description']\n",
    "    groups.loc[q_var] = {'Description': q_var_description, 'Group': 'Activity'}\n",
    "\n",
    "    # Define factor structure using 'factor_specification' function\n",
    "    factors = factor_specification(groups, additional_factors=additional_factors, q_var_description = q_var_description)\n",
    "    \n",
    "    # Loop over each vintage, fit model, and store forecast\n",
    "    forecasts = {}\n",
    "    for vint in vintages:\n",
    "        # Get monthly and quarterly datasets for this vintage\n",
    "        if with_text:\n",
    "            endog_m = dta[vint].combined.loc[start:, :]\n",
    "        else:\n",
    "            endog_m = dta[vint].dta_m.loc[start:, :]\n",
    "        endog_q = dta[vint].dta_q.loc[start:, [q_var_description]]\n",
    "        \n",
    "        # Construct the Dynamic Factor Model\n",
    "        model = sm.tsa.DynamicFactorMQ(\n",
    "            endog_m, endog_quarterly=endog_q,\n",
    "            factors=factors, factor_orders=factor_orders,\n",
    "            factor_multiplicities=factor_multiplicities)\n",
    "        \n",
    "        # Fit the model\n",
    "        results = model.fit(disp=10)\n",
    "        \n",
    "        # Get the point forecast for the quarter of interest\n",
    "        point_forecast = results.get_prediction(start=forecast_month, end=forecast_month).predicted_mean[q_var_description]\n",
    "        forecast_value = point_forecast.loc[forecast_month]\n",
    "        forecasts[vint] = forecast_value\n",
    "        \n",
    "    return forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3414ac",
   "metadata": {},
   "source": [
    "## 4. Testing the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c15d5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM start iterations, llf=-2404.3\n",
      "EM iteration 10, llf=-2353.5, convergence criterion=9.2478e-05\n",
      "EM iteration 20, llf=-2352.2, convergence criterion=3.5772e-05\n",
      "EM iteration 30, llf=-2351.6, convergence criterion=1.806e-05\n",
      "EM iteration 40, llf=-2351.3, convergence criterion=1.0695e-05\n",
      "EM iteration 50, llf=-2351.1, convergence criterion=7.133e-06\n",
      "EM iteration 60, llf=-2351, convergence criterion=5.152e-06\n",
      "EM iteration 70, llf=-2350.9, convergence criterion=3.9323e-06\n",
      "EM iteration 80, llf=-2350.8, convergence criterion=3.1216e-06\n",
      "EM iteration 90, llf=-2350.7, convergence criterion=2.5504e-06\n",
      "EM iteration 100, llf=-2350.7, convergence criterion=2.1297e-06\n",
      "EM iteration 110, llf=-2350.6, convergence criterion=1.8088e-06\n",
      "EM iteration 120, llf=-2350.6, convergence criterion=1.5573e-06\n",
      "EM iteration 130, llf=-2350.6, convergence criterion=1.3558e-06\n",
      "EM iteration 140, llf=-2350.5, convergence criterion=1.1914e-06\n",
      "EM iteration 150, llf=-2350.5, convergence criterion=1.0552e-06\n",
      "EM converged at iteration 155, llf=-2350.5, convergence criterion=9.9573e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-2404.3\n",
      "EM iteration 10, llf=-2353.5, convergence criterion=9.2478e-05\n",
      "EM iteration 20, llf=-2352.2, convergence criterion=3.5772e-05\n",
      "EM iteration 30, llf=-2351.6, convergence criterion=1.806e-05\n",
      "EM iteration 40, llf=-2351.3, convergence criterion=1.0695e-05\n",
      "EM iteration 50, llf=-2351.1, convergence criterion=7.133e-06\n",
      "EM iteration 60, llf=-2351, convergence criterion=5.152e-06\n",
      "EM iteration 70, llf=-2350.9, convergence criterion=3.9323e-06\n",
      "EM iteration 80, llf=-2350.8, convergence criterion=3.1216e-06\n",
      "EM iteration 90, llf=-2350.7, convergence criterion=2.5504e-06\n",
      "EM iteration 100, llf=-2350.7, convergence criterion=2.1297e-06\n",
      "EM iteration 110, llf=-2350.6, convergence criterion=1.8088e-06\n",
      "EM iteration 120, llf=-2350.6, convergence criterion=1.5573e-06\n",
      "EM iteration 130, llf=-2350.6, convergence criterion=1.3558e-06\n",
      "EM iteration 140, llf=-2350.5, convergence criterion=1.1914e-06\n",
      "EM iteration 150, llf=-2350.5, convergence criterion=1.0552e-06\n",
      "EM converged at iteration 155, llf=-2350.5, convergence criterion=9.9573e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-2417.1\n",
      "EM iteration 10, llf=-2366.1, convergence criterion=9.0483e-05\n",
      "EM iteration 20, llf=-2364.9, convergence criterion=3.5133e-05\n",
      "EM iteration 30, llf=-2364.3, convergence criterion=1.7831e-05\n",
      "EM iteration 40, llf=-2364, convergence criterion=1.0606e-05\n",
      "EM iteration 50, llf=-2363.8, convergence criterion=7.1011e-06\n",
      "EM iteration 60, llf=-2363.6, convergence criterion=5.1448e-06\n",
      "EM iteration 70, llf=-2363.5, convergence criterion=3.9355e-06\n",
      "EM iteration 80, llf=-2363.5, convergence criterion=3.1286e-06\n",
      "EM iteration 90, llf=-2363.4, convergence criterion=2.5582e-06\n",
      "EM iteration 100, llf=-2363.3, convergence criterion=2.1368e-06\n",
      "EM iteration 110, llf=-2363.3, convergence criterion=1.8146e-06\n",
      "EM iteration 120, llf=-2363.3, convergence criterion=1.5617e-06\n",
      "EM iteration 130, llf=-2363.2, convergence criterion=1.3588e-06\n",
      "EM iteration 140, llf=-2363.2, convergence criterion=1.1932e-06\n",
      "EM iteration 150, llf=-2363.2, convergence criterion=1.056e-06\n",
      "EM converged at iteration 155, llf=-2363.2, convergence criterion=9.9609e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-2418.6\n",
      "EM iteration 10, llf=-2367.6, convergence criterion=9.1258e-05\n",
      "EM iteration 20, llf=-2366.3, convergence criterion=3.5141e-05\n",
      "EM iteration 30, llf=-2365.8, convergence criterion=1.7746e-05\n",
      "EM iteration 40, llf=-2365.4, convergence criterion=1.055e-05\n",
      "EM iteration 50, llf=-2365.2, convergence criterion=7.0597e-06\n",
      "EM iteration 60, llf=-2365.1, convergence criterion=5.112e-06\n",
      "EM iteration 70, llf=-2365, convergence criterion=3.9084e-06\n",
      "EM iteration 80, llf=-2364.9, convergence criterion=3.1054e-06\n",
      "EM iteration 90, llf=-2364.9, convergence criterion=2.5379e-06\n",
      "EM iteration 100, llf=-2364.8, convergence criterion=2.1188e-06\n",
      "EM iteration 110, llf=-2364.8, convergence criterion=1.7986e-06\n",
      "EM iteration 120, llf=-2364.7, convergence criterion=1.5472e-06\n",
      "EM iteration 130, llf=-2364.7, convergence criterion=1.3457e-06\n",
      "EM iteration 140, llf=-2364.7, convergence criterion=1.1813e-06\n",
      "EM iteration 150, llf=-2364.6, convergence criterion=1.0451e-06\n",
      "EM converged at iteration 154, llf=-2364.6, convergence criterion=9.9715e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-2434.7\n",
      "EM iteration 10, llf=-2383.5, convergence criterion=9.4099e-05\n",
      "EM iteration 20, llf=-2382.2, convergence criterion=3.5842e-05\n",
      "EM iteration 30, llf=-2381.6, convergence criterion=1.7925e-05\n",
      "EM iteration 40, llf=-2381.3, convergence criterion=1.0564e-05\n",
      "EM iteration 50, llf=-2381.1, convergence criterion=7.0196e-06\n",
      "EM iteration 60, llf=-2381, convergence criterion=5.0576e-06\n",
      "EM iteration 70, llf=-2380.9, convergence criterion=3.8543e-06\n",
      "EM iteration 80, llf=-2380.8, convergence criterion=3.0572e-06\n",
      "EM iteration 90, llf=-2380.7, convergence criterion=2.4971e-06\n",
      "EM iteration 100, llf=-2380.7, convergence criterion=2.0854e-06\n",
      "EM iteration 110, llf=-2380.6, convergence criterion=1.7718e-06\n",
      "EM iteration 120, llf=-2380.6, convergence criterion=1.5262e-06\n",
      "EM iteration 130, llf=-2380.5, convergence criterion=1.3294e-06\n",
      "EM iteration 140, llf=-2380.5, convergence criterion=1.1689e-06\n",
      "EM iteration 150, llf=-2380.5, convergence criterion=1.036e-06\n",
      "EM converged at iteration 154, llf=-2380.5, convergence criterion=9.8915e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-2434.7\n",
      "EM iteration 10, llf=-2383.5, convergence criterion=9.4099e-05\n",
      "EM iteration 20, llf=-2382.2, convergence criterion=3.5842e-05\n",
      "EM iteration 30, llf=-2381.6, convergence criterion=1.7925e-05\n",
      "EM iteration 40, llf=-2381.3, convergence criterion=1.0564e-05\n",
      "EM iteration 50, llf=-2381.1, convergence criterion=7.0196e-06\n",
      "EM iteration 60, llf=-2381, convergence criterion=5.0576e-06\n",
      "EM iteration 70, llf=-2380.9, convergence criterion=3.8543e-06\n",
      "EM iteration 80, llf=-2380.8, convergence criterion=3.0572e-06\n",
      "EM iteration 90, llf=-2380.7, convergence criterion=2.4971e-06\n",
      "EM iteration 100, llf=-2380.7, convergence criterion=2.0854e-06\n",
      "EM iteration 110, llf=-2380.6, convergence criterion=1.7718e-06\n",
      "EM iteration 120, llf=-2380.6, convergence criterion=1.5262e-06\n",
      "EM iteration 130, llf=-2380.5, convergence criterion=1.3294e-06\n",
      "EM iteration 140, llf=-2380.5, convergence criterion=1.1689e-06\n",
      "EM iteration 150, llf=-2380.5, convergence criterion=1.036e-06\n",
      "EM converged at iteration 154, llf=-2380.5, convergence criterion=9.8915e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-2446.9\n",
      "EM iteration 10, llf=-2395.7, convergence criterion=8.7239e-05\n",
      "EM iteration 20, llf=-2394.4, convergence criterion=3.3826e-05\n",
      "EM iteration 30, llf=-2393.9, convergence criterion=1.7259e-05\n",
      "EM iteration 40, llf=-2393.6, convergence criterion=1.0343e-05\n",
      "EM iteration 50, llf=-2393.4, convergence criterion=6.9648e-06\n",
      "EM iteration 60, llf=-2393.2, convergence criterion=5.0637e-06\n",
      "EM iteration 70, llf=-2393.1, convergence criterion=3.8786e-06\n",
      "EM iteration 80, llf=-2393, convergence criterion=3.0818e-06\n",
      "EM iteration 90, llf=-2393, convergence criterion=2.5152e-06\n",
      "EM iteration 100, llf=-2392.9, convergence criterion=2.0951e-06\n",
      "EM iteration 110, llf=-2392.9, convergence criterion=1.7734e-06\n",
      "EM iteration 120, llf=-2392.8, convergence criterion=1.5209e-06\n",
      "EM iteration 130, llf=-2392.8, convergence criterion=1.3187e-06\n",
      "EM iteration 140, llf=-2392.8, convergence criterion=1.1541e-06\n",
      "EM iteration 150, llf=-2392.7, convergence criterion=1.0182e-06\n",
      "EM converged at iteration 152, llf=-2392.7, convergence criterion=9.9392e-07 < tolerance=1e-06\n"
     ]
    }
   ],
   "source": [
    "# --- Example usage ---\n",
    "\n",
    "# Define inputs\n",
    "forecast_month = '2008-03'                            # target forecast quarter (2008Q1)\n",
    "q_var = 'GDP'                                         # quarterly variable being forecasted\n",
    "additional_factors = None                             # or \"all\" or e.g. ['Labor market'] or 'HardSurveys+Text'\n",
    "factor_multiplicities = {'Global': 1}                 # One Global factor\n",
    "factor_orders = {'Global': 3}                         # Global factor follows AR(3) process\n",
    "start = '1991-04'\n",
    "text_type = \"topics\"\n",
    "estimation_period = \"2007\"\n",
    "num_topics = \"200\"\n",
    "source = \"all\"\n",
    "with_text = True\n",
    "only_text = True\n",
    "\n",
    "# Run the forecast function\n",
    "forecasts = get_forecasts(forecast_month = forecast_month, q_var = q_var, additional_factors = additional_factors, \n",
    "                          factor_multiplicities = factor_multiplicities, factor_orders = factor_orders, start = start,\n",
    "                          text_type = text_type, estimation_period = estimation_period, num_topics = num_topics, source = source,\n",
    "                          with_text = with_text, only_text = only_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b505d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2008-01-01': np.float64(2.362276153737156),\n",
       " '2008-01-16': np.float64(2.362276153737156),\n",
       " '2008-02-01': np.float64(1.8512675006274713),\n",
       " '2008-02-16': np.float64(1.8158190369680773),\n",
       " '2008-03-01': np.float64(1.6498734299580078),\n",
       " '2008-03-16': np.float64(1.6498734299580078),\n",
       " '2008-04-01': np.float64(1.6668235845101256)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nowcasting",
   "language": "python",
   "name": "nowcasting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
