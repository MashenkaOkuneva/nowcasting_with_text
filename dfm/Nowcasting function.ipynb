{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc015c2b",
   "metadata": {},
   "source": [
    "Below is an explanation of how the notebook evolved - from testing individual steps to combining everything into one main function that produces a GDP/Investment/Consumption forecast for a target quarter (e.g., 2008Q1) based on 7 data vintages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce6a51",
   "metadata": {},
   "source": [
    "## 1. Define necessary inputs\n",
    "\n",
    "Before building the final function, I first specified the inputs required for the forecasting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda9694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input for the function\n",
    "\n",
    "# Target forecast quarter\n",
    "forecast_month = '2008-03' # 2008Q1\n",
    "# Quarterly variable being forecasted\n",
    "q_var = 'GDP'\n",
    "\n",
    "# Factor options:\n",
    "# 1. Specify whether group-specific factors are included\n",
    "aditional_factors = None  # Use only the global factor\n",
    "# 2. Number of factors from each group\n",
    "factor_multiplicities = {'Global': 1}  # Only one global factor\n",
    "# 3. Specify the lag order of the (vector) autoregressions that govern the dynamics of the factors\n",
    "factor_orders = {'Global': 3} # Global factor follows univariate AR(3) process \n",
    "\n",
    "# Start of the estimation sample\n",
    "start = '1991-04'\n",
    "\n",
    "# Text options:\n",
    "text_type = \"topics\"           # Type of text variables (e.g., \"topics\", \"topics_BPW\", \"topics_uncertainty\")\n",
    "estimation_period = \"2007\"     # Period marker (e.g., \"2007\" or \"2018\") indicating estimation sample for topics\n",
    "num_topics = \"200\"             # Number of topics in the LDA model (e.g., \"200\" or \"100\")\n",
    "source = \"all\"                 # \"all\", \"dpa\", \"hb\", \"sz\", or \"welt\"\n",
    "with_text = True               # If True, forecast with text variables; if False, forecast without"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f168e47",
   "metadata": {},
   "source": [
    "## 2. Test the forecasting process for one specific quarter\n",
    "\n",
    "Before generalizing the code into a function that works for any quarter, I first tested the entire process for one specific quarter (2008Q1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171e2f1",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8873ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform(column, transforms):\n",
    "    transformation = transforms[column.name]\n",
    "    # For quarterly data like GDP, we will compute\n",
    "    # annualized percent changes\n",
    "    mult = 4 if column.index.freqstr[0] == 'Q' else 1\n",
    "    \n",
    "    # 1 => No transformation\n",
    "    if transformation == 1:\n",
    "        pass\n",
    "    # 2 => First difference\n",
    "    elif transformation == 2:\n",
    "        column = column.diff()\n",
    "    # 3 => Log first difference, multiplied by 100\n",
    "    #      (i.e. approximate percent change)\n",
    "    #      with optional multiplier for annualization\n",
    "    elif transformation == 3:\n",
    "        column = np.log(column).diff() * 100 * mult\n",
    "        \n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40117e37",
   "metadata": {},
   "source": [
    "### Load vintage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2ffc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(vintage, q_var):\n",
    "    \n",
    "    # - Monthly data --------------------------------------------------------------\n",
    "    # 1. Download data\n",
    "    orig_m = (pd.read_csv(f'../data/vintages_monthly/{vintage}.csv')\n",
    "                .dropna(how='all'))\n",
    "    \n",
    "    # 2. Extract transformation information\n",
    "    transform_m = orig_m.iloc[0, 1:]\n",
    "    orig_m = orig_m.iloc[1:]\n",
    "\n",
    "    # 3. Extract the date as an index\n",
    "    orig_m.index = pd.PeriodIndex(orig_m.date.tolist(), freq='M')\n",
    "    orig_m.drop('date', axis=1, inplace=True)\n",
    "\n",
    "    # 4. Apply the transformations\n",
    "    dta_m = orig_m.apply(transform, axis=0,\n",
    "                         transforms=transform_m)\n",
    "\n",
    "    # - Quarterly data --------------------------------------------------------------\n",
    "    # 1. Download data\n",
    "    orig_q = (pd.read_csv(f'../data/vintages_quarterly/{vintage}.csv')\n",
    "                .dropna(how='all'))\n",
    "    # Keep the quarterly variable that will be forecasted\n",
    "    orig_q = orig_q[['date', q_var]]\n",
    "\n",
    "    # 2. Extract transformation information\n",
    "    transform_q = orig_q.iloc[0, 1:]\n",
    "    orig_q = orig_q.iloc[1:]\n",
    "\n",
    "    # 3. Extract the date as an index\n",
    "    orig_q.index = pd.PeriodIndex(orig_q.date.tolist(), freq='Q')\n",
    "    orig_q.drop('date', axis=1, inplace=True)\n",
    "\n",
    "    # 4. Apply the transformations\n",
    "    dta_q = orig_q.apply(transform, axis=0,\n",
    "                          transforms=transform_q)\n",
    "\n",
    "    # - Output datasets ------------------------------------------------------\n",
    "    return types.SimpleNamespace(\n",
    "        orig_m=orig_m, orig_q=orig_q,\n",
    "        dta_m=dta_m, transform_m=transform_m,\n",
    "        dta_q=dta_q, transform_q=transform_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a1855",
   "metadata": {},
   "source": [
    "### Generating vintage dates\n",
    "\n",
    "The `vintage_dates()` function creates a list of 7 vintage date strings based on the target forecast month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97acdd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def vintage_dates(target_month):\n",
    "    \"\"\"\n",
    "    Given a target month string in \"YYYY-MM\" format, this function returns a list of 7 vintage date strings.\n",
    "    \n",
    "    For example, if target_month is \"2008-03\", it returns:\n",
    "      ['2008-01-01', '2008-01-16', '2008-02-01', '2008-02-16', '2008-03-01', '2008-03-16', '2008-04-01']\n",
    "    \"\"\"\n",
    "    # Convert target_month to a date object representing the first day of that month\n",
    "    target_date = datetime.strptime(target_month + \"-01\", \"%Y-%m-%d\").date()\n",
    "    \n",
    "    # The sequence should start two months before the target month\n",
    "    start_month = target_date - relativedelta(months=2)\n",
    "    \n",
    "    vintages = []\n",
    "    current = start_month\n",
    "    # For each month from start_month to target_date (inclusive), add the 1st and 16th day of the month\n",
    "    for _ in range(3):  # there are three months in a quarter\n",
    "        first_day = current\n",
    "        mid_month = current.replace(day=16)\n",
    "        vintages.append(first_day.strftime(\"%Y-%m-%d\"))\n",
    "        vintages.append(mid_month.strftime(\"%Y-%m-%d\"))\n",
    "        current += relativedelta(months=1)\n",
    "        \n",
    "    # Append the first day of the month following the target month\n",
    "    next_month = target_date + relativedelta(months=1)\n",
    "    vintages.append(next_month.strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "    return vintages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc196fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2008-01-01',\n",
       " '2008-01-16',\n",
       " '2008-02-01',\n",
       " '2008-02-16',\n",
       " '2008-03-01',\n",
       " '2008-03-16',\n",
       " '2008-04-01']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test this helper function ##\n",
    "vintages = vintage_dates(forecast_month)\n",
    "vintages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e25b9",
   "metadata": {},
   "source": [
    "### Load, transform, and organize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53cbe09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConstrProd</th>\n",
       "      <th>IP</th>\n",
       "      <th>ConstrNO</th>\n",
       "      <th>INO</th>\n",
       "      <th>ConstrTurn</th>\n",
       "      <th>ITurn</th>\n",
       "      <th>RetTurn</th>\n",
       "      <th>CPI</th>\n",
       "      <th>CPIEN</th>\n",
       "      <th>PPI</th>\n",
       "      <th>...</th>\n",
       "      <th>CorpDebt</th>\n",
       "      <th>PublicDebt</th>\n",
       "      <th>ifoIndTradeClimate</th>\n",
       "      <th>ifoIndTradeCurrent</th>\n",
       "      <th>ifoIndTradeExp</th>\n",
       "      <th>GfKBCE</th>\n",
       "      <th>GfKIE</th>\n",
       "      <th>GfKWtB</th>\n",
       "      <th>GfKCCI</th>\n",
       "      <th>ESI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-02</th>\n",
       "      <td>-22.030935</td>\n",
       "      <td>-1.923136</td>\n",
       "      <td>1.114218</td>\n",
       "      <td>-2.912262</td>\n",
       "      <td>-9.087038</td>\n",
       "      <td>-1.834914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.249688</td>\n",
       "      <td>0.371978</td>\n",
       "      <td>0.106326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-03</th>\n",
       "      <td>14.671067</td>\n",
       "      <td>-0.215983</td>\n",
       "      <td>-1.301134</td>\n",
       "      <td>0.118134</td>\n",
       "      <td>5.836116</td>\n",
       "      <td>-0.495051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>-0.212766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-04</th>\n",
       "      <td>-1.023550</td>\n",
       "      <td>-0.542007</td>\n",
       "      <td>-2.942785</td>\n",
       "      <td>-1.307208</td>\n",
       "      <td>5.134932</td>\n",
       "      <td>-0.872280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497513</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.742709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-05</th>\n",
       "      <td>-1.138140</td>\n",
       "      <td>-1.423122</td>\n",
       "      <td>5.437140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089188</td>\n",
       "      <td>-0.125235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.247832</td>\n",
       "      <td>0.245399</td>\n",
       "      <td>0.105652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ConstrProd        IP  ConstrNO       INO  ConstrTurn     ITurn  \\\n",
       "1991-01         NaN       NaN       NaN       NaN         NaN       NaN   \n",
       "1991-02  -22.030935 -1.923136  1.114218 -2.912262   -9.087038 -1.834914   \n",
       "1991-03   14.671067 -0.215983 -1.301134  0.118134    5.836116 -0.495051   \n",
       "1991-04   -1.023550 -0.542007 -2.942785 -1.307208    5.134932 -0.872280   \n",
       "1991-05   -1.138140 -1.423122  5.437140  0.000000    0.089188 -0.125235   \n",
       "\n",
       "         RetTurn       CPI     CPIEN       PPI  ...  CorpDebt  PublicDebt  \\\n",
       "1991-01      NaN       NaN       NaN       NaN  ...       NaN         NaN   \n",
       "1991-02      NaN  0.249688  0.371978  0.106326  ...     -0.28        -0.5   \n",
       "1991-03      NaN  0.000000  0.370600 -0.212766  ...     -0.33        -0.1   \n",
       "1991-04      NaN  0.497513  0.369231  0.742709  ...     -0.03         0.0   \n",
       "1991-05      NaN  0.247832  0.245399  0.105652  ...     -0.05         0.0   \n",
       "\n",
       "         ifoIndTradeClimate  ifoIndTradeCurrent  ifoIndTradeExp  GfKBCE  \\\n",
       "1991-01                 NaN                 NaN             NaN     NaN   \n",
       "1991-02                 0.3                 2.0            -1.3     NaN   \n",
       "1991-03                -2.9                -5.8            -0.3     NaN   \n",
       "1991-04                 0.1                -1.7             1.8     NaN   \n",
       "1991-05                -2.5                -5.1             0.0     NaN   \n",
       "\n",
       "         GfKIE  GfKWtB  GfKCCI  ESI  \n",
       "1991-01    NaN     NaN     NaN  NaN  \n",
       "1991-02    NaN     NaN     NaN -2.5  \n",
       "1991-03    NaN     NaN     NaN -3.9  \n",
       "1991-04    NaN     NaN     NaN  0.3  \n",
       "1991-05    NaN     NaN     NaN  0.1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the vintages of data\n",
    "dta = {date: load_data(date, q_var = q_var)\n",
    "       for date in vintages}\n",
    "dta['2008-01-01'].dta_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90e2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_data(vintage, q_var, text_type=\"topics\", estimation_period=\"2007\", num_topics=\"200\", source=\"all\"):\n",
    "    \n",
    "    # 1. Download data\n",
    "    filename = f'../data/vintages_monthly_{q_var}_{text_type}_{estimation_period}_{num_topics}_{source}/{vintage}.csv'\n",
    "    orig_text = pd.read_csv(filename).dropna(how='all')\n",
    "    \n",
    "    # 2. Extract transformation information\n",
    "    transform_text = orig_text.iloc[0, 1:]\n",
    "    orig_text = orig_text.iloc[1:]\n",
    "    \n",
    "    # 3. Extract the date as an index\n",
    "    orig_text.index = pd.PeriodIndex(orig_text.date.tolist(), freq='M')\n",
    "    orig_text.drop('date', axis=1, inplace=True)\n",
    "    \n",
    "    # 4. Apply the transformations\n",
    "    dta_text = orig_text.apply(transform, axis=0, transforms=transform_text)\n",
    "    \n",
    "     # - Output datasets \n",
    "    return types.SimpleNamespace(\n",
    "        orig_text=orig_text, \n",
    "        dta_text=dta_text, \n",
    "        transform_text=transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c8d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "if with_text:\n",
    "    # Loop over each vintage and load the corresponding text data\n",
    "    for date in vintages:\n",
    "        # Load text data for each vintage\n",
    "        text_obj = load_text_data(date, q_var=q_var, \n",
    "                                  text_type=text_type, \n",
    "                                  estimation_period=estimation_period, \n",
    "                                  num_topics=num_topics,\n",
    "                                  source=source)\n",
    "\n",
    "        # Merge the monthly economic data (dta_m) with the text data\n",
    "        dta[date].combined = dta[date].dta_m.merge(text_obj.dta_text, left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23808f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the definitions Excel file for monthly variables\n",
    "defn_m = pd.read_excel('../data/data_monthly/variables_definitions.xlsx')\n",
    "# Set the index to the \"Mnemonic\" column\n",
    "defn_m.index = defn_m['Mnemonic']\n",
    "\n",
    "# Load the definitions Excel file for quarterly variables\n",
    "defn_q = pd.read_excel('../data/data_quarterly/variables_definitions.xlsx')\n",
    "defn_q = defn_q[defn_q.Mnemonic == q_var]\n",
    "defn_q.index = defn_q.Mnemonic\n",
    "\n",
    "if with_text:\n",
    "    # Load the definitions Excel file for text variables\n",
    "    defn_text = pd.read_excel(f'../data/data_text/variables_definitions_{q_var}_{text_type}_{estimation_period}_{num_topics}_{source}.xlsx')\n",
    "    defn_text.index = defn_text['Mnemonic']\n",
    "\n",
    "    # Combine the definitions for monthly economic and text variables\n",
    "    defn_combined = pd.concat([defn_m, defn_text])\n",
    "\n",
    "# Replace the names of the columns in each monthly and quarterly dataset\n",
    "map_m = defn_m['Description'].to_dict()\n",
    "map_q = defn_q['Description'].to_dict()\n",
    "if with_text:\n",
    "    # When forecasting with text variables, also replace the names in the combined dataset\n",
    "    map_combined = defn_combined['Description'].to_dict()\n",
    "    \n",
    "for date, value in dta.items():\n",
    "    value.orig_m.columns = value.orig_m.columns.map(map_m)\n",
    "    value.dta_m.columns = value.dta_m.columns.map(map_m)\n",
    "    value.orig_q.columns = value.orig_q.columns.map(map_q)\n",
    "    value.dta_q.columns = value.dta_q.columns.map(map_q)\n",
    "    if with_text:\n",
    "        value.combined.columns = value.combined.columns.map(map_combined)\n",
    "    \n",
    "# Re-order the variables according to the definition file\n",
    "# (which is ordered by group)\n",
    "if with_text:\n",
    "    columns = [name for name in defn_combined['Description']\n",
    "           if name in dta[vintages[0]].combined.columns]\n",
    "    for date in dta.keys():\n",
    "        dta[date].combined = dta[date].combined.reindex(columns, axis=1)\n",
    "else:\n",
    "    columns = [name for name in defn_m['Description']\n",
    "               if name in dta[vintages[0]].dta_m.columns]\n",
    "    for date in dta.keys():\n",
    "        dta[date].dta_m = dta[date].dta_m.reindex(columns, axis=1)\n",
    "    \n",
    "# Get the mapping of variable mnemonic to group name, for monthly variables\n",
    "if with_text:\n",
    "    groups = defn_combined[['Description', 'Group']].copy()\n",
    "else:\n",
    "    groups = defn_m[['Description', 'Group']].copy()\n",
    "\n",
    "# Add our quarterly variable into the \"Activity\" group\n",
    "q_var_description = defn_q.loc[q_var, 'Description']\n",
    "groups.loc[q_var] = {'Description': q_var_description, 'Group': 'Activity'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f83937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Production in main construction industry</th>\n",
       "      <th>Industrial production index</th>\n",
       "      <th>New orders for main construction industry</th>\n",
       "      <th>New orders for industry</th>\n",
       "      <th>Main construction industry turnover</th>\n",
       "      <th>Industry turnover</th>\n",
       "      <th>Retail turnover excluding cars</th>\n",
       "      <th>Consumer price index</th>\n",
       "      <th>Consumer price index, excluding energy</th>\n",
       "      <th>Producer price index</th>\n",
       "      <th>...</th>\n",
       "      <th>Crisis</th>\n",
       "      <th>Corporate Growth</th>\n",
       "      <th>Banking</th>\n",
       "      <th>Policy Measures</th>\n",
       "      <th>Problem Solving</th>\n",
       "      <th>US Politics</th>\n",
       "      <th>Commodity Markets</th>\n",
       "      <th>Economic Growth</th>\n",
       "      <th>Media Coverage of Plans and Rumors</th>\n",
       "      <th>Steel Industry Restructuring and Downsizing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-02</th>\n",
       "      <td>-22.030935</td>\n",
       "      <td>-1.923136</td>\n",
       "      <td>1.114218</td>\n",
       "      <td>-2.912262</td>\n",
       "      <td>-9.087038</td>\n",
       "      <td>-1.834914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.249688</td>\n",
       "      <td>0.371978</td>\n",
       "      <td>0.106326</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-03</th>\n",
       "      <td>14.671067</td>\n",
       "      <td>-0.215983</td>\n",
       "      <td>-1.301134</td>\n",
       "      <td>0.118134</td>\n",
       "      <td>5.836116</td>\n",
       "      <td>-0.495051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>-0.212766</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-04</th>\n",
       "      <td>-1.023550</td>\n",
       "      <td>-0.542007</td>\n",
       "      <td>-2.942785</td>\n",
       "      <td>-1.307208</td>\n",
       "      <td>5.134932</td>\n",
       "      <td>-0.872280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.497513</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>0.742709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>-0.002345</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.001255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-05</th>\n",
       "      <td>-1.138140</td>\n",
       "      <td>-1.423122</td>\n",
       "      <td>5.437140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089188</td>\n",
       "      <td>-0.125235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.247832</td>\n",
       "      <td>0.245399</td>\n",
       "      <td>0.105652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>-0.001558</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>-0.001922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Production in main construction industry  \\\n",
       "1991-01                                       NaN   \n",
       "1991-02                                -22.030935   \n",
       "1991-03                                 14.671067   \n",
       "1991-04                                 -1.023550   \n",
       "1991-05                                 -1.138140   \n",
       "\n",
       "         Industrial production index  \\\n",
       "1991-01                          NaN   \n",
       "1991-02                    -1.923136   \n",
       "1991-03                    -0.215983   \n",
       "1991-04                    -0.542007   \n",
       "1991-05                    -1.423122   \n",
       "\n",
       "         New orders for main construction industry  New orders for industry  \\\n",
       "1991-01                                        NaN                      NaN   \n",
       "1991-02                                   1.114218                -2.912262   \n",
       "1991-03                                  -1.301134                 0.118134   \n",
       "1991-04                                  -2.942785                -1.307208   \n",
       "1991-05                                   5.437140                 0.000000   \n",
       "\n",
       "         Main construction industry turnover  Industry turnover  \\\n",
       "1991-01                                  NaN                NaN   \n",
       "1991-02                            -9.087038          -1.834914   \n",
       "1991-03                             5.836116          -0.495051   \n",
       "1991-04                             5.134932          -0.872280   \n",
       "1991-05                             0.089188          -0.125235   \n",
       "\n",
       "         Retail turnover excluding cars  Consumer price index  \\\n",
       "1991-01                             NaN                   NaN   \n",
       "1991-02                             NaN              0.249688   \n",
       "1991-03                             NaN              0.000000   \n",
       "1991-04                             NaN              0.497513   \n",
       "1991-05                             NaN              0.247832   \n",
       "\n",
       "         Consumer price index, excluding energy  Producer price index  ...  \\\n",
       "1991-01                                     NaN                   NaN  ...   \n",
       "1991-02                                0.371978              0.106326  ...   \n",
       "1991-03                                0.370600             -0.212766  ...   \n",
       "1991-04                                0.369231              0.742709  ...   \n",
       "1991-05                                0.245399              0.105652  ...   \n",
       "\n",
       "           Crisis  Corporate Growth   Banking  Policy Measures  \\\n",
       "1991-01       NaN               NaN       NaN              NaN   \n",
       "1991-02       NaN               NaN       NaN              NaN   \n",
       "1991-03       NaN               NaN       NaN              NaN   \n",
       "1991-04 -0.000184         -0.000235  0.000082         0.002874   \n",
       "1991-05 -0.000025          0.000014 -0.000108         0.001311   \n",
       "\n",
       "         Problem Solving  US Politics  Commodity Markets  Economic Growth  \\\n",
       "1991-01              NaN          NaN                NaN              NaN   \n",
       "1991-02              NaN          NaN                NaN              NaN   \n",
       "1991-03              NaN          NaN                NaN              NaN   \n",
       "1991-04         0.002470    -0.002345           0.000179         0.000093   \n",
       "1991-05         0.001076    -0.001558           0.000183         0.000077   \n",
       "\n",
       "         Media Coverage of Plans and Rumors  \\\n",
       "1991-01                                 NaN   \n",
       "1991-02                                 NaN   \n",
       "1991-03                                 NaN   \n",
       "1991-04                            0.000047   \n",
       "1991-05                            0.000231   \n",
       "\n",
       "         Steel Industry Restructuring and Downsizing  \n",
       "1991-01                                          NaN  \n",
       "1991-02                                          NaN  \n",
       "1991-03                                          NaN  \n",
       "1991-04                                    -0.001255  \n",
       "1991-05                                    -0.001922  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "if with_text:\n",
    "    display(dta['2008-01-01'].combined.head())\n",
    "else:\n",
    "    display(dta['2008-01-01'].dta_m.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6260b6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mnemonic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ConstrProd</th>\n",
       "      <td>Production in main construction industry</td>\n",
       "      <td>Activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IP</th>\n",
       "      <td>Industrial production index</td>\n",
       "      <td>Activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ConstrNO</th>\n",
       "      <td>New orders for main construction industry</td>\n",
       "      <td>Activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INO</th>\n",
       "      <td>New orders for industry</td>\n",
       "      <td>Activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ConstrTurn</th>\n",
       "      <td>Main construction industry turnover</td>\n",
       "      <td>Activity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description     Group\n",
       "Mnemonic                                                       \n",
       "ConstrProd   Production in main construction industry  Activity\n",
       "IP                        Industrial production index  Activity\n",
       "ConstrNO    New orders for main construction industry  Activity\n",
       "INO                           New orders for industry  Activity\n",
       "ConstrTurn        Main construction industry turnover  Activity"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d26a71",
   "metadata": {},
   "source": [
    "### Defining the factor structure\n",
    "\n",
    "I use a helper function `factor_specification` that maps each variable (based on its description and group) to the factors that will load on it. This allows flexibility - for instance, using only a global factor, or global plus group-specific factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "639e64d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_specification(groups, additional_factors=None):\n",
    "    \"\"\"\n",
    "    Construct a dictionary mapping each variable\n",
    "    to a list of factors according to the desired specification.\n",
    "\n",
    "    Parameters:\n",
    "      groups : pandas.DataFrame\n",
    "          DataFrame that must contain at least two columns: \n",
    "          \"Description\" (the variable name) and \"Group\" (its group, e.g., 'Activity', 'Prices', 'Labor market',\n",
    "          'Financial', 'Surveys', or 'Text').\n",
    "      \n",
    "      additional_factors : None, str, or list of str\n",
    "          - If None or an empty list, only \"Global\" is included.\n",
    "          - If \"all\", then each variable loads on a global factor and a group-specific factor.\n",
    "          - If a list (e.g. ['Labor market'] or ['Prices', 'Labor market']), \n",
    "            then a variable gets the extra factor only if its group is in that list.\n",
    "            \n",
    "    Returns:\n",
    "      A dictionary where keys are the variable names and values are lists of factors.\n",
    "    \"\"\"\n",
    "    factors = {}\n",
    "    for _, row in groups.iterrows():\n",
    "        desc = row['Description']\n",
    "        group = row['Group']\n",
    "        facs = ['Global']  # Always include the global factor\n",
    "        \n",
    "        if additional_factors:\n",
    "            # If \"all\" then include each variable's own group as a factor.\n",
    "            if additional_factors == \"all\":\n",
    "                facs.append(group)\n",
    "            # If additional_factors is a list, only include if the group's name is in the list.\n",
    "            elif isinstance(additional_factors, list) and group in additional_factors:\n",
    "                facs.append(group)\n",
    "        factors[desc] = facs\n",
    "    return factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3dc9358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Production in main construction industry': ['Global'],\n",
       " 'Industrial production index': ['Global'],\n",
       " 'New orders for main construction industry': ['Global'],\n",
       " 'New orders for industry': ['Global'],\n",
       " 'Main construction industry turnover': ['Global'],\n",
       " 'Industry turnover': ['Global'],\n",
       " 'Retail turnover excluding cars': ['Global'],\n",
       " 'Consumer price index': ['Global'],\n",
       " 'Consumer price index, excluding energy': ['Global'],\n",
       " 'Producer price index': ['Global'],\n",
       " 'Producer price index, excluding energy': ['Global'],\n",
       " 'Export price index': ['Global'],\n",
       " 'Import price index': ['Global'],\n",
       " 'Hours worked: manufacturing': ['Global'],\n",
       " 'Hours worked: construction': ['Global'],\n",
       " 'Employment': ['Global'],\n",
       " 'Gross wages and salaries: manufacturing and mining': ['Global'],\n",
       " 'Gross wages and salaries: construction': ['Global'],\n",
       " 'CDAX': ['Global'],\n",
       " 'Government bond yields (1-year)': ['Global'],\n",
       " 'Government bond yields (5-years)': ['Global'],\n",
       " 'Government bond yields (10-years)': ['Global'],\n",
       " 'Nominal effective exchange rate (narrow)': ['Global'],\n",
       " 'Nominal effective exchange rate (broad)': ['Global'],\n",
       " 'Yields on debt securities issued by residents': ['Global'],\n",
       " 'Yields on bank debt securities': ['Global'],\n",
       " 'Yields on corporate debt securities': ['Global'],\n",
       " 'Yields on public debt securities': ['Global'],\n",
       " 'ifo: industry and trade, climate': ['Global'],\n",
       " 'ifo: industry and trade, current situation': ['Global'],\n",
       " 'ifo: industry and trade, expectations': ['Global'],\n",
       " 'GfK: business cycle expectations': ['Global'],\n",
       " 'GfK: income expectations': ['Global'],\n",
       " 'GfK: willigness-to-buy': ['Global'],\n",
       " 'GfK: consumer climate indicator': ['Global'],\n",
       " 'Economics Sentiment Indicator': ['Global'],\n",
       " 'Crisis': ['Global'],\n",
       " 'Corporate Growth': ['Global'],\n",
       " 'Banking': ['Global'],\n",
       " 'Policy Measures': ['Global'],\n",
       " 'Problem Solving': ['Global'],\n",
       " 'US Politics': ['Global'],\n",
       " 'Commodity Markets': ['Global'],\n",
       " 'Economic Growth': ['Global'],\n",
       " 'Media Coverage of Plans and Rumors': ['Global'],\n",
       " 'Steel Industry Restructuring and Downsizing': ['Global'],\n",
       " 'Gross Domestic Product': ['Global']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors = factor_specification(groups, additional_factors = aditional_factors)\n",
    "factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda9502b",
   "metadata": {},
   "source": [
    "### Constructing the Dynamic Factor Model and Extracting Forecasts\n",
    "\n",
    "For each vintage, the model produces a point forecast for GDP/Consumption/Investment for the target quarter. We collect these forecasts into a dictionary for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb2749",
   "metadata": {},
   "source": [
    "#### First vintage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53fb6614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM start iterations, llf=-11583\n",
      "EM iteration 10, llf=-11386, convergence criterion=3.4709e-05\n",
      "EM iteration 20, llf=-11384, convergence criterion=8.2151e-06\n",
      "EM iteration 30, llf=-11383, convergence criterion=4.9428e-06\n",
      "EM iteration 40, llf=-11383, convergence criterion=3.0726e-06\n",
      "EM iteration 50, llf=-11383, convergence criterion=2.0253e-06\n",
      "EM iteration 60, llf=-11382, convergence criterion=1.4076e-06\n",
      "EM iteration 70, llf=-11382, convergence criterion=1.0232e-06\n",
      "EM converged at iteration 71, llf=-11382, convergence criterion=9.9322e-07 < tolerance=1e-06\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Get monthly and quarterly datasets\n",
    "if with_text:\n",
    "    endog_m = dta[vintages[0]].combined.loc[start:, :]\n",
    "else:\n",
    "    endog_m = dta[vintages[0]].dta_m.loc[start:, :]\n",
    "endog_q = dta[vintages[0]].dta_q.loc[start:, [q_var_description]]\n",
    "\n",
    "# Construct the dynamic factor model\n",
    "model = sm.tsa.DynamicFactorMQ(\n",
    "    endog_m, endog_quarterly=endog_q,\n",
    "    factors=factors, factor_orders=factor_orders,\n",
    "    factor_multiplicities=factor_multiplicities)\n",
    "\n",
    "results = model.fit(disp=10)\n",
    "\n",
    "# The point forecast for the quarter of interest\n",
    "point_forecast = results.get_prediction(start = forecast_month, end = forecast_month).predicted_mean[q_var_description]\n",
    "\n",
    "forecast_value = point_forecast.loc[forecast_month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13d7046c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.080087022033421)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b01c3cb",
   "metadata": {},
   "source": [
    "#### All vintages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9d4ecf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM start iterations, llf=-11583\n",
      "EM iteration 10, llf=-11386, convergence criterion=3.4709e-05\n",
      "EM iteration 20, llf=-11384, convergence criterion=8.2151e-06\n",
      "EM iteration 30, llf=-11383, convergence criterion=4.9428e-06\n",
      "EM iteration 40, llf=-11383, convergence criterion=3.0726e-06\n",
      "EM iteration 50, llf=-11383, convergence criterion=2.0253e-06\n",
      "EM iteration 60, llf=-11382, convergence criterion=1.4076e-06\n",
      "EM iteration 70, llf=-11382, convergence criterion=1.0232e-06\n",
      "EM converged at iteration 71, llf=-11382, convergence criterion=9.9322e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-11595\n",
      "EM iteration 10, llf=-11397, convergence criterion=3.4891e-05\n",
      "EM iteration 20, llf=-11396, convergence criterion=8.2245e-06\n",
      "EM iteration 30, llf=-11395, convergence criterion=4.946e-06\n",
      "EM iteration 40, llf=-11395, convergence criterion=3.0742e-06\n",
      "EM iteration 50, llf=-11394, convergence criterion=2.0263e-06\n",
      "EM iteration 60, llf=-11394, convergence criterion=1.4082e-06\n",
      "EM iteration 70, llf=-11394, convergence criterion=1.0236e-06\n",
      "EM converged at iteration 71, llf=-11394, convergence criterion=9.936e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-11648\n",
      "EM iteration 10, llf=-11448, convergence criterion=3.6663e-05\n",
      "EM iteration 20, llf=-11446, convergence criterion=8.3006e-06\n",
      "EM iteration 30, llf=-11445, convergence criterion=4.9625e-06\n",
      "EM iteration 40, llf=-11445, convergence criterion=3.0822e-06\n",
      "EM iteration 50, llf=-11445, convergence criterion=2.0312e-06\n",
      "EM iteration 60, llf=-11445, convergence criterion=1.4117e-06\n",
      "EM iteration 70, llf=-11444, convergence criterion=1.0261e-06\n",
      "EM converged at iteration 71, llf=-11444, convergence criterion=9.9603e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-11656\n",
      "EM iteration 10, llf=-11456, convergence criterion=3.6619e-05\n",
      "EM iteration 20, llf=-11455, convergence criterion=8.3551e-06\n",
      "EM iteration 30, llf=-11454, convergence criterion=4.9484e-06\n",
      "EM iteration 40, llf=-11453, convergence criterion=3.074e-06\n",
      "EM iteration 50, llf=-11453, convergence criterion=2.027e-06\n",
      "EM iteration 60, llf=-11453, convergence criterion=1.4095e-06\n",
      "EM iteration 70, llf=-11453, convergence criterion=1.025e-06\n",
      "EM converged at iteration 71, llf=-11453, convergence criterion=9.9504e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-11720\n",
      "EM iteration 10, llf=-11517, convergence criterion=4.133e-05\n",
      "EM iteration 20, llf=-11515, convergence criterion=8.7672e-06\n",
      "EM iteration 30, llf=-11514, convergence criterion=5.0374e-06\n",
      "EM iteration 40, llf=-11514, convergence criterion=3.1121e-06\n",
      "EM iteration 50, llf=-11513, convergence criterion=2.0478e-06\n",
      "EM iteration 60, llf=-11513, convergence criterion=1.4221e-06\n",
      "EM iteration 70, llf=-11513, convergence criterion=1.0333e-06\n",
      "EM converged at iteration 72, llf=-11513, convergence criterion=9.7389e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-11729\n",
      "EM iteration 10, llf=-11525, convergence criterion=4.2265e-05\n",
      "EM iteration 20, llf=-11523, convergence criterion=8.8278e-06\n",
      "EM iteration 30, llf=-11523, convergence criterion=5.0482e-06\n",
      "EM iteration 40, llf=-11522, convergence criterion=3.1164e-06\n",
      "EM iteration 50, llf=-11522, convergence criterion=2.05e-06\n",
      "EM iteration 60, llf=-11522, convergence criterion=1.4235e-06\n",
      "EM iteration 70, llf=-11522, convergence criterion=1.0341e-06\n",
      "EM converged at iteration 72, llf=-11522, convergence criterion=9.7465e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-11780\n",
      "EM iteration 10, llf=-11579, convergence criterion=3.9085e-05\n",
      "EM iteration 20, llf=-11577, convergence criterion=8.5739e-06\n",
      "EM iteration 30, llf=-11576, convergence criterion=4.9816e-06\n",
      "EM iteration 40, llf=-11576, convergence criterion=3.0812e-06\n",
      "EM iteration 50, llf=-11576, convergence criterion=2.0277e-06\n",
      "EM iteration 60, llf=-11575, convergence criterion=1.4083e-06\n",
      "EM iteration 70, llf=-11575, convergence criterion=1.0233e-06\n",
      "EM converged at iteration 71, llf=-11575, convergence criterion=9.9327e-07 < tolerance=1e-06\n"
     ]
    }
   ],
   "source": [
    "# Prepare an empty dictionary to store forecast values based on each vintage\n",
    "forecasts = {}\n",
    "\n",
    "for vint in vintages:\n",
    "    # Get monthly and quarterly datasets for this vintage\n",
    "    if with_text:\n",
    "        endog_m = dta[vint].combined.loc[start:, :]\n",
    "    else:\n",
    "        endog_m = dta[vint].dta_m.loc[start:, :]\n",
    "    endog_q = dta[vint].dta_q.loc[start:, [q_var_description]]\n",
    "    \n",
    "    # Construct the dynamic factor model\n",
    "    model = sm.tsa.DynamicFactorMQ(\n",
    "        endog_m, endog_quarterly=endog_q,\n",
    "        factors=factors, factor_orders=factor_orders,\n",
    "        factor_multiplicities=factor_multiplicities)\n",
    "    \n",
    "    # Fit the model\n",
    "    results = model.fit(disp=10)\n",
    "    \n",
    "    # Get the point forecast for the quarter of interest\n",
    "    point_forecast = results.get_prediction(start=forecast_month, end=forecast_month).predicted_mean[q_var_description]\n",
    "    \n",
    "    # Extract the forecast value using the forecast_date index\n",
    "    forecast_value = point_forecast.loc[forecast_month]\n",
    "    \n",
    "    # Save the forecast value associated with the vintage\n",
    "    forecasts[vint] = forecast_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b0f4b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2008-01-01': np.float64(2.080087022033421),\n",
       " '2008-01-16': np.float64(2.071246180516665),\n",
       " '2008-02-01': np.float64(0.7016388921889369),\n",
       " '2008-02-16': np.float64(0.7061645651329682),\n",
       " '2008-03-01': np.float64(0.9205644639905985),\n",
       " '2008-03-16': np.float64(0.9484462069224506),\n",
       " '2008-04-01': np.float64(1.0032944724059165)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5b93e",
   "metadata": {},
   "source": [
    "## 3. Combining everything into the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a72a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "# --- Helper functions ---\n",
    "\n",
    "def transform(column, transforms):\n",
    "    transformation = transforms[column.name]\n",
    "    # For quarterly data like GDP, we will compute\n",
    "    # annualized percent changes\n",
    "    mult = 4 if column.index.freqstr[0] == 'Q' else 1\n",
    "    \n",
    "    # 1 => No transformation\n",
    "    if transformation == 1:\n",
    "        pass\n",
    "    # 2 => First difference\n",
    "    elif transformation == 2:\n",
    "        column = column.diff()\n",
    "    # 3 => Log first difference, multiplied by 100\n",
    "    #      (i.e. approximate percent change)\n",
    "    #      with optional multiplier for annualization\n",
    "    elif transformation == 3:\n",
    "        column = np.log(column).diff() * 100 * mult\n",
    "        \n",
    "    return column\n",
    "\n",
    "def load_data(vintage, q_var):\n",
    "    \n",
    "    # - Monthly data --------------------------------------------------------------\n",
    "    # 1. Download data\n",
    "    orig_m = (pd.read_csv(f'../data/vintages_monthly/{vintage}.csv')\n",
    "                .dropna(how='all'))\n",
    "    \n",
    "    # 2. Extract transformation information\n",
    "    transform_m = orig_m.iloc[0, 1:]\n",
    "    orig_m = orig_m.iloc[1:]\n",
    "\n",
    "    # 3. Extract the date as an index\n",
    "    orig_m.index = pd.PeriodIndex(orig_m.date.tolist(), freq='M')\n",
    "    orig_m.drop('date', axis=1, inplace=True)\n",
    "\n",
    "    # 4. Apply the transformations\n",
    "    dta_m = orig_m.apply(transform, axis=0,\n",
    "                         transforms=transform_m)\n",
    "\n",
    "    # - Quarterly data --------------------------------------------------------------\n",
    "    # 1. Download data\n",
    "    orig_q = (pd.read_csv(f'../data/vintages_quarterly/{vintage}.csv')\n",
    "                .dropna(how='all'))\n",
    "    # Keep the quarterly variable that will be forecasted\n",
    "    orig_q = orig_q[['date', q_var]]\n",
    "\n",
    "    # 2. Extract transformation information\n",
    "    transform_q = orig_q.iloc[0, 1:]\n",
    "    orig_q = orig_q.iloc[1:]\n",
    "\n",
    "    # 3. Extract the date as an index\n",
    "    orig_q.index = pd.PeriodIndex(orig_q.date.tolist(), freq='Q')\n",
    "    orig_q.drop('date', axis=1, inplace=True)\n",
    "\n",
    "    # 4. Apply the transformations\n",
    "    dta_q = orig_q.apply(transform, axis=0,\n",
    "                          transforms=transform_q)\n",
    "\n",
    "    # - Output datasets ------------------------------------------------------\n",
    "    return types.SimpleNamespace(\n",
    "        orig_m=orig_m, orig_q=orig_q,\n",
    "        dta_m=dta_m, transform_m=transform_m,\n",
    "        dta_q=dta_q, transform_q=transform_q)\n",
    "\n",
    "def vintage_dates(target_month):\n",
    "    \"\"\"\n",
    "    Given a target month string in \"YYYY-MM\" format, this function returns a list of 7 vintage date strings.\n",
    "    \n",
    "    For example, if target_month is \"2008-03\", it returns:\n",
    "      ['2008-01-01', '2008-01-16', '2008-02-01', '2008-02-16', '2008-03-01', '2008-03-16', '2008-04-01']\n",
    "    \"\"\"\n",
    "    # Convert target_month to a date object representing the first day of that month\n",
    "    target_date = datetime.strptime(target_month + \"-01\", \"%Y-%m-%d\").date()\n",
    "    \n",
    "    # The sequence should start two months before the target month\n",
    "    start_month = target_date - relativedelta(months=2)\n",
    "    \n",
    "    vintages = []\n",
    "    current = start_month\n",
    "    # For each month from start_month to target_date (inclusive), add the 1st and 16th day of the month\n",
    "    for _ in range(3):  # there are three months in a quarter\n",
    "        first_day = current\n",
    "        mid_month = current.replace(day=16)\n",
    "        vintages.append(first_day.strftime(\"%Y-%m-%d\"))\n",
    "        vintages.append(mid_month.strftime(\"%Y-%m-%d\"))\n",
    "        current += relativedelta(months=1)\n",
    "        \n",
    "    # Append the first day of the month following the target month\n",
    "    next_month = target_date + relativedelta(months=1)\n",
    "    vintages.append(next_month.strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "    return vintages\n",
    "\n",
    "def load_text_data(vintage, q_var, text_type=\"topics\", estimation_period=\"2007\", num_topics=\"200\", source=\"all\"):\n",
    "    \n",
    "    # 1. Download data\n",
    "    filename = f'../data/vintages_monthly_{q_var}_{text_type}_{estimation_period}_{num_topics}_{source}/{vintage}.csv'\n",
    "    orig_text = pd.read_csv(filename).dropna(how='all')\n",
    "    \n",
    "    # 2. Extract transformation information\n",
    "    transform_text = orig_text.iloc[0, 1:]\n",
    "    orig_text = orig_text.iloc[1:]\n",
    "    \n",
    "    # 3. Extract the date as an index\n",
    "    orig_text.index = pd.PeriodIndex(orig_text.date.tolist(), freq='M')\n",
    "    orig_text.drop('date', axis=1, inplace=True)\n",
    "    \n",
    "    # 4. Apply the transformations\n",
    "    dta_text = orig_text.apply(transform, axis=0, transforms=transform_text)\n",
    "    \n",
    "     # - Output datasets \n",
    "    return types.SimpleNamespace(\n",
    "        orig_text=orig_text, \n",
    "        dta_text=dta_text, \n",
    "        transform_text=transform_text)\n",
    "\n",
    "def factor_specification(groups, additional_factors=None):\n",
    "    \"\"\"\n",
    "    Construct a dictionary mapping each variable\n",
    "    to a list of factors according to the desired specification.\n",
    "\n",
    "    Parameters:\n",
    "      groups : pandas.DataFrame\n",
    "          DataFrame that must contain at least two columns: \n",
    "          \"Description\" (the variable name) and \"Group\" (its group, e.g., 'Activity', 'Prices', 'Labor market',\n",
    "          'Financial', 'Surveys', or 'Text').\n",
    "      \n",
    "      additional_factors : None, str, or list of str\n",
    "          - If None or an empty list, only \"Global\" is included.\n",
    "          - If \"all\", then each variable loads on a global factor and a group-specific factor.\n",
    "          - If a list (e.g. ['Labor market'] or ['Prices', 'Labor market']), \n",
    "            then a variable gets the extra factor only if its group is in that list.\n",
    "            \n",
    "    Returns:\n",
    "      A dictionary where keys are the variable names and values are lists of factors.\n",
    "    \"\"\"\n",
    "    factors = {}\n",
    "    for _, row in groups.iterrows():\n",
    "        desc = row['Description']\n",
    "        group = row['Group']\n",
    "        facs = ['Global']  # Always include the global factor\n",
    "        \n",
    "        if additional_factors:\n",
    "            # If \"all\" then include each variable's own group as a factor.\n",
    "            if additional_factors == \"all\":\n",
    "                facs.append(group)\n",
    "            # If additional_factors is a list, only include if the group's name is in the list.\n",
    "            elif isinstance(additional_factors, list) and group in additional_factors:\n",
    "                facs.append(group)\n",
    "        factors[desc] = facs\n",
    "    return factors\n",
    "\n",
    "# --- Main function that produces forecasts for the quarter of interest based on 7 vintages ---\n",
    "def get_forecasts(forecast_month, q_var, additional_factors, factor_multiplicities, factor_orders, start, text_type=\"topics\",\n",
    "                 estimation_period=\"2007\", num_topics=\"200\", source=\"all\", with_text=False):\n",
    "    \"\"\"\n",
    "    Given the input parameters, this function:\n",
    "      - Generates the list of vintage dates for the forecast month.\n",
    "      - Loads monthly and quarterly datasets for each vintage.\n",
    "      - Loads variable definition files, renames variables in the original dataset and reorders them.\n",
    "      - Specifies the factor structure based on additional_factors.\n",
    "      - Constructs and fits a monthly Dynamic Factor Model for each vintage.\n",
    "      - Returns a dictionary of forecast values (keyed by vintage) for GDP/Consumption/Investment.\n",
    "    \n",
    "    Parameters:\n",
    "      forecast_month: string in \"YYYY-MM\" format (e.g., \"2008-03\")\n",
    "      q_var: string, quarterly variable being forecasted (e.g., 'GDP')\n",
    "      additional_factors: None, \"all\", or a list of groups (e.g., ['Labor market'])\n",
    "      factor_multiplicities: dictionary (e.g., {'Global': 1})\n",
    "      factor_orders: dictionary (e.g., {'Global': 3})\n",
    "      start: string indicating start date for estimation sample (e.g., \"1991-02\")\n",
    "      text_type: Type of text variables (e.g., \"topics\", \"topics_BPW\", \"topics_uncertainty\")\n",
    "      estimation_period: Period marker (e.g., \"2007\" or \"2018\") indicating estimation sample for topics\n",
    "      num_topics: Number of topics in the model (e.g., \"200\" or \"100\")\n",
    "      source: \"all\", \"dpa\", \"hb\", \"sz\", or \"welt\"\n",
    "      with_text: If True, forecast with text variables; if False, forecast without\n",
    "    \n",
    "    Returns:\n",
    "      forecasts: dict mapping vintage date (string) to forecast value (for GDP/Consumption/Investment)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate vintage dates\n",
    "    vintages = vintage_dates(forecast_month)\n",
    "    \n",
    "    # Load data for each vintage\n",
    "    dta = {vint: load_data(vint, q_var = q_var) for vint in vintages}\n",
    "    \n",
    "    if with_text:\n",
    "        # Loop over each vintage and load the corresponding text data\n",
    "        for vint in vintages:\n",
    "            # Load text data for each vintage\n",
    "            text_obj = load_text_data(vint, q_var=q_var, \n",
    "                                      text_type=text_type, \n",
    "                                      estimation_period=estimation_period, \n",
    "                                      num_topics=num_topics,\n",
    "                                      source=source)\n",
    "\n",
    "            # Merge the monthly economic data (dta_m) with the text data\n",
    "            dta[vint].combined = dta[vint].dta_m.merge(text_obj.dta_text, left_index=True, right_index=True, how='outer')\n",
    "    \n",
    "    # Load definitions for monthly and quarterly variables\n",
    "    defn_m = pd.read_excel('../data/data_monthly/variables_definitions.xlsx')\n",
    "    defn_m.index = defn_m['Mnemonic']\n",
    "    defn_q = pd.read_excel('../data/data_quarterly/variables_definitions.xlsx')\n",
    "    defn_q = defn_q[defn_q.Mnemonic == q_var]\n",
    "    defn_q.index = defn_q['Mnemonic']\n",
    "    if with_text:\n",
    "        # Load the definitions Excel file for text variables\n",
    "        defn_text = pd.read_excel(f'../data/data_text/variables_definitions_{q_var}_{text_type}_{estimation_period}_{num_topics}_{source}.xlsx')\n",
    "        defn_text.index = defn_text['Mnemonic']\n",
    "\n",
    "        # Combine the definitions for monthly economic and text variables\n",
    "        defn_combined = pd.concat([defn_m, defn_text])\n",
    "         \n",
    "    # Create mapping from mnemonic to description\n",
    "    map_m = defn_m['Description'].to_dict()\n",
    "    map_q = defn_q['Description'].to_dict()\n",
    "    if with_text:\n",
    "        # When forecasting with text variables, also replace the names in the combined dataset\n",
    "        map_combined = defn_combined['Description'].to_dict()\n",
    "    \n",
    "    # Replace column names for monthly and quarterly datasets in each vintage\n",
    "    for vint in dta.keys():\n",
    "        dta[vint].orig_m.columns = dta[vint].orig_m.columns.map(map_m)\n",
    "        dta[vint].dta_m.columns = dta[vint].dta_m.columns.map(map_m)\n",
    "        dta[vint].orig_q.columns = dta[vint].orig_q.columns.map(map_q)\n",
    "        dta[vint].dta_q.columns = dta[vint].dta_q.columns.map(map_q)\n",
    "        if with_text:\n",
    "            dta[vint].combined.columns = dta[vint].combined.columns.map(map_combined)\n",
    "    \n",
    "    # Re-order the monthly data columns based on the definitions file order\n",
    "    if with_text:\n",
    "        columns = [name for name in defn_combined['Description']\n",
    "               if name in dta[vintages[0]].combined.columns]\n",
    "        for vint in dta.keys():\n",
    "            dta[vint].combined = dta[vint].combined.reindex(columns, axis=1)\n",
    "    else:\n",
    "        columns = [name for name in defn_m['Description']\n",
    "                   if name in dta[vintages[0]].dta_m.columns]\n",
    "        for vint in dta.keys():\n",
    "            dta[vint].dta_m = dta[vint].dta_m.reindex(columns, axis=1)\n",
    "        \n",
    "    # Get groups (variable -> group) mapping from monthly definitions\n",
    "    if with_text:\n",
    "        groups = defn_combined[['Description', 'Group']].copy()\n",
    "    else:\n",
    "        groups = defn_m[['Description', 'Group']].copy()\n",
    "    \n",
    "    # Add our quarterly variable into the \"Activity\" group\n",
    "    q_var_description = defn_q.loc[q_var, 'Description']\n",
    "    groups.loc[q_var] = {'Description': q_var_description, 'Group': 'Activity'}\n",
    "\n",
    "    # Define factor structure using 'factor_specification' function\n",
    "    factors = factor_specification(groups, additional_factors=additional_factors)\n",
    "    \n",
    "    # Loop over each vintage, fit model, and store forecast\n",
    "    forecasts = {}\n",
    "    for vint in vintages:\n",
    "        # Get monthly and quarterly datasets for this vintage\n",
    "        if with_text:\n",
    "            endog_m = dta[vint].combined.loc[start:, :]\n",
    "        else:\n",
    "            endog_m = dta[vint].dta_m.loc[start:, :]\n",
    "        endog_q = dta[vint].dta_q.loc[start:, [q_var_description]]\n",
    "        \n",
    "        # Construct the Dynamic Factor Model\n",
    "        model = sm.tsa.DynamicFactorMQ(\n",
    "            endog_m, endog_quarterly=endog_q,\n",
    "            factors=factors, factor_orders=factor_orders,\n",
    "            factor_multiplicities=factor_multiplicities)\n",
    "        \n",
    "        # Fit the model\n",
    "        results = model.fit(disp=10)\n",
    "        \n",
    "        # Get the point forecast for the quarter of interest\n",
    "        point_forecast = results.get_prediction(start=forecast_month, end=forecast_month).predicted_mean[q_var_description]\n",
    "        forecast_value = point_forecast.loc[forecast_month]\n",
    "        forecasts[vint] = forecast_value\n",
    "        \n",
    "    return forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3414ac",
   "metadata": {},
   "source": [
    "## 4. Testing the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c15d5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM start iterations, llf=-11583\n",
      "EM iteration 10, llf=-11386, convergence criterion=3.4709e-05\n",
      "EM iteration 20, llf=-11384, convergence criterion=8.2151e-06\n",
      "EM iteration 30, llf=-11383, convergence criterion=4.9428e-06\n",
      "EM iteration 40, llf=-11383, convergence criterion=3.0726e-06\n",
      "EM iteration 50, llf=-11383, convergence criterion=2.0253e-06\n",
      "EM iteration 60, llf=-11382, convergence criterion=1.4076e-06\n",
      "EM iteration 70, llf=-11382, convergence criterion=1.0232e-06\n",
      "EM converged at iteration 71, llf=-11382, convergence criterion=9.9322e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-11595\n",
      "EM iteration 10, llf=-11397, convergence criterion=3.4891e-05\n",
      "EM iteration 20, llf=-11396, convergence criterion=8.2245e-06\n",
      "EM iteration 30, llf=-11395, convergence criterion=4.946e-06\n",
      "EM iteration 40, llf=-11395, convergence criterion=3.0742e-06\n",
      "EM iteration 50, llf=-11394, convergence criterion=2.0263e-06\n",
      "EM iteration 60, llf=-11394, convergence criterion=1.4082e-06\n",
      "EM iteration 70, llf=-11394, convergence criterion=1.0236e-06\n",
      "EM converged at iteration 71, llf=-11394, convergence criterion=9.936e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-11648\n",
      "EM iteration 10, llf=-11448, convergence criterion=3.6663e-05\n",
      "EM iteration 20, llf=-11446, convergence criterion=8.3006e-06\n",
      "EM iteration 30, llf=-11445, convergence criterion=4.9625e-06\n",
      "EM iteration 40, llf=-11445, convergence criterion=3.0822e-06\n",
      "EM iteration 50, llf=-11445, convergence criterion=2.0312e-06\n",
      "EM iteration 60, llf=-11445, convergence criterion=1.4117e-06\n",
      "EM iteration 70, llf=-11444, convergence criterion=1.0261e-06\n",
      "EM converged at iteration 71, llf=-11444, convergence criterion=9.9603e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-11656\n",
      "EM iteration 10, llf=-11456, convergence criterion=3.6619e-05\n",
      "EM iteration 20, llf=-11455, convergence criterion=8.3551e-06\n",
      "EM iteration 30, llf=-11454, convergence criterion=4.9484e-06\n",
      "EM iteration 40, llf=-11453, convergence criterion=3.074e-06\n",
      "EM iteration 50, llf=-11453, convergence criterion=2.027e-06\n",
      "EM iteration 60, llf=-11453, convergence criterion=1.4095e-06\n",
      "EM iteration 70, llf=-11453, convergence criterion=1.025e-06\n",
      "EM converged at iteration 71, llf=-11453, convergence criterion=9.9504e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-11720\n",
      "EM iteration 10, llf=-11517, convergence criterion=4.133e-05\n",
      "EM iteration 20, llf=-11515, convergence criterion=8.7672e-06\n",
      "EM iteration 30, llf=-11514, convergence criterion=5.0374e-06\n",
      "EM iteration 40, llf=-11514, convergence criterion=3.1121e-06\n",
      "EM iteration 50, llf=-11513, convergence criterion=2.0478e-06\n",
      "EM iteration 60, llf=-11513, convergence criterion=1.4221e-06\n",
      "EM iteration 70, llf=-11513, convergence criterion=1.0333e-06\n",
      "EM converged at iteration 72, llf=-11513, convergence criterion=9.7389e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-11729\n",
      "EM iteration 10, llf=-11525, convergence criterion=4.2265e-05\n",
      "EM iteration 20, llf=-11523, convergence criterion=8.8278e-06\n",
      "EM iteration 30, llf=-11523, convergence criterion=5.0482e-06\n",
      "EM iteration 40, llf=-11522, convergence criterion=3.1164e-06\n",
      "EM iteration 50, llf=-11522, convergence criterion=2.05e-06\n",
      "EM iteration 60, llf=-11522, convergence criterion=1.4235e-06\n",
      "EM iteration 70, llf=-11522, convergence criterion=1.0341e-06\n",
      "EM converged at iteration 72, llf=-11522, convergence criterion=9.7465e-07 < tolerance=1e-06\n",
      "EM start iterations, llf=-11780\n",
      "EM iteration 10, llf=-11579, convergence criterion=3.9085e-05\n",
      "EM iteration 20, llf=-11577, convergence criterion=8.5739e-06\n",
      "EM iteration 30, llf=-11576, convergence criterion=4.9816e-06\n",
      "EM iteration 40, llf=-11576, convergence criterion=3.0812e-06\n",
      "EM iteration 50, llf=-11576, convergence criterion=2.0277e-06\n",
      "EM iteration 60, llf=-11575, convergence criterion=1.4083e-06\n",
      "EM iteration 70, llf=-11575, convergence criterion=1.0233e-06\n",
      "EM converged at iteration 71, llf=-11575, convergence criterion=9.9327e-07 < tolerance=1e-06\n"
     ]
    }
   ],
   "source": [
    "# --- Example usage ---\n",
    "\n",
    "# Define inputs\n",
    "forecast_month = '2008-03'         # target forecast quarter (2008Q1)\n",
    "q_var = 'GDP'                      # quarterly variable being forecasted\n",
    "additional_factors = None          # or \"all\" or e.g. ['Labor market']\n",
    "factor_multiplicities = {'Global': 1}\n",
    "factor_orders = {'Global': 3}\n",
    "start = '1991-04'\n",
    "text_type = \"topics\"\n",
    "estimation_period = \"2007\"\n",
    "num_topics = \"200\"\n",
    "source = \"all\"\n",
    "with_text = True\n",
    "\n",
    "# Run the forecast function\n",
    "forecasts = get_forecasts(forecast_month = forecast_month, q_var = q_var, additional_factors = additional_factors, \n",
    "                          factor_multiplicities = factor_multiplicities, factor_orders = factor_orders, start = start,\n",
    "                          text_type = text_type, estimation_period = estimation_period, num_topics = num_topics, source = source,\n",
    "                          with_text = with_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b505d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2008-01-01': np.float64(2.080087022033421),\n",
       " '2008-01-16': np.float64(2.071246180516665),\n",
       " '2008-02-01': np.float64(0.7016388921889369),\n",
       " '2008-02-16': np.float64(0.7061645651329682),\n",
       " '2008-03-01': np.float64(0.9205644639905985),\n",
       " '2008-03-16': np.float64(0.9484462069224506),\n",
       " '2008-04-01': np.float64(1.0032944724059165)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nowcasting",
   "language": "python",
   "name": "nowcasting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
