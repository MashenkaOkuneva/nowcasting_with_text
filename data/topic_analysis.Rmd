---
title: "Analyzing topics"
output:
  html_document:
    df_print: paged
  'html_notebook:': default
  html_notebook: default
---

This notebook illustrates how we transform the raw daily time series of topics before estimating the monthly factor model. Additionally, it also calculates principal component estimates of transformed series and analyzes their correlation with quarterly variables.  

```{r echo=T, message = FALSE, warning = FALSE}
rm(list = ls())
library(ggplot2)
library(lubridate)
library(dplyr)
library(tidyr)
library(fredmdr)
library(bundesbank)
library(tibble)
library(ggsci)
```

## Load topics

```{r}
sample_start = c("1991-02-01")
K = 30

df_raw <- read.csv("../topics/daily_topics.csv")

# add date and quarter variable
df_raw %>%
  mutate(date = make_date(year = df_raw$year, 
                          month = df_raw$month, 
                          day = df_raw$day),
         quarter = ceiling(month / 3)) %>% 
  select(date, year, quarter, month, day, everything()) -> df_topics  

# get rid of raw df
rm(df_raw)

# extend series with NA to 7-day week 
dates_tmp <- data.frame(date = seq(min(df_topics$date), 
                                   max(df_topics$date), 
                                   by = "days")
)

dates_tmp %>% 
  mutate(year = year(date),
         month = month(date),
         quarter = ceiling(month / 3),
         day = day(date)) %>%
  merge(df_topics, by = c("date", "year", "quarter", "month", "day"), all.x = T) -> df_topics

# get rid of dates_tmp
rm(dates_tmp)

# col indices corresponding to topics
ind_topics <- which(grepl("T", names(df_topics)))

# adjust sample (leaving K additional rows at start which will be removed after smoothing)
df_topics %>% filter(date >= as.Date(sample_start) - days(K)) -> df_topics

# inspect first rows of df_topics
head(df_topics)
```

## Pre-processing and transformations

The following plot shows a representative topic series. It is extremely noisy and characterized by a slow-moving trend (but not necessarily linear!). In this section, we illustrate how to adjust the series in order to estimate the factor model at the monthly frequency. 

```{r}
ggplot(df_topics, aes(x = date, y = T2))+geom_line(alpha = 0.5)
```

```{r}
# select only topics
dat <- df_topics[, ind_topics]

# store pattern of missings
ind_NA <- is.na(dat)
colnames(ind_NA) <- names(df_topics)[grepl("T", names(df_topics))]
```


### Smoothing the raw topics

To smooth the topics, we calculate a 30-day backward looking moving average. 

`rollmean` function that calculates the recursive $K$-th order rolling mean, i.e. $\hat{y}_t = \frac{1}{K} \sum_{k=0}^K y_{t-k}$. Allows for `NA` in the series. 
```{r}
rollmean <- function(x, k){
  xroll <- array(NA, c(length(x)))
  for (t in seq(k, length(x)))
    xroll[t] <- mean(x[(t-k+1):t], na.rm = TRUE)
  
  return(xroll)
}
```


```{r}
# moving average
dat_ma <- apply(dat, c(2), rollmean, k = K)
```

### Removing trends

`bw_filter` function that calculates the bi-weight filter as in [Stock and Watson (2012)](https://www.princeton.edu/~mwatson/papers/Stock_Watson_Disentangling_BPEA_2012.pdf) and [Stock and Watson (2016)](https://www.princeton.edu/~mwatson/papers/Stock_Watson_DFM_HOM_030916.pdf). This removes long-run trends in the series but is more flexible than a linear time trend. While in principle two-sided, the filter becomes increasingly one-sided when approaching the endpoints. The function allows for `NA` in the series but only at the beginning!  
```{r}
bw_filter <- function(y, bw)
{
  # compute un-normalized weights
  j <- seq(-bw, bw, 1) 
  omeg = (1 - (j/bw) ^ 2) ^ 2  
  
  # check for NA's in y
  n_NA <- sum(is.na(y)) 
  y_noNA <- y[(n_NA + 1) : length(y)]
  Nt <- length(y_noNA)
  
  # loop over t
  tau <- mat.or.vec(length(y_noNA), 1)
  for (t in 1 : length(y_noNA)) {
    # case distinction
    if (t <= bw) {
      
      indY <- c(1 : (2 * bw - (bw - t)))
      indOmeg <- c((bw - t + 2):(2 * bw + 1)) 
      kap <- 1 / ( sum(omeg[indOmeg]))
      tau[ t ] <- kap * omeg[indOmeg] %*% y_noNA[indY] 
      
    } else if (t > (Nt - bw)) {
      
      indY <- c((t - bw) : Nt)
      indOmeg <- c(1 : (bw + 1 + (Nt - t)))
      kap <- 1 / ( sum( omeg[indOmeg] ) )
      tau[t] <- kap * omeg[indOmeg] %*% y_noNA[indY] 
      
    } else {
      
      indY <- seq(t - bw, t + bw, 1)
      indOmeg <- c( 1 : (2 * bw + 1))
      kap <- 1 / (sum(omeg[indOmeg]))
      tau[t] <- kap * omeg[indOmeg] %*% y_noNA[indY]  
    }
  }
  return(c(rep(NA, times = n_NA), tau))
}
```


```{r}
bw = 1200

# bi-weight filter
dat_bw <- apply(dat_ma, c(2), bw_filter, bw = bw)

# de-trended topics
dat_detrend <- dat_ma - dat_bw

# reimpose NA pattern
dat_detrend_NA <- dat_detrend
dat_detrend_NA[ind_NA] <- NA

# store in df_topics_trafo
df_topics_trafo <- df_topics
df_topics_trafo[ind_topics] <- dat_detrend_NA

# rm first K rows
df_topics_trafo <- df_topics_trafo[seq(K+1, nrow(df_topics_trafo)), ]
```

### Plot selected topics

```{r}
df_orig <- as.data.frame(dat)
df_orig$date <- df_topics$date
df_orig %>% 
  pivot_longer(cols = -date, names_to = "topics", values_to = "vals") %>%
  mutate(series = "original") -> df_orig

df_trafo <- as.data.frame(df_topics_trafo)
df_trafo %>% 
  pivot_longer(cols = -date, names_to = "topics", values_to = "vals") %>%
  mutate(series = "final") -> df_trafo

df_ma <- as.data.frame(dat_ma)
df_ma$date <- df_topics$date
df_ma %>% 
  pivot_longer(cols = -date, names_to = "topics", values_to = "vals") %>%
  mutate(series = "smoothed") -> df_ma

df_bw <- as.data.frame(dat_bw)
df_bw$date <- df_topics$date
df_bw %>% 
  pivot_longer(cols = -date, names_to = "topics", values_to = "vals") %>%
  mutate(series = "filtered") -> df_bw

# merge into one df
df_plot <- rbind(df_ma, df_bw)
df_plot <- rbind(df_plot, df_orig)
df_plot <- rbind(df_plot, df_trafo)

# rm df's
rm(df_ma, df_bw, df_orig, df_trafo)

# convert series to factor and reorder levels
df_plot$series <- as.factor(df_plot$series)
df_plot$series = factor(df_plot$series,levels(df_plot$series)[c(3, 4, 1, 2)])
```

```{r}
ggplot(filter(df_plot, topics %in% c("T2", "T9", "T23", "T27", "T28", "T29")), 
       aes(x = date, y = vals, 
           group = series, 
           col = series, 
           linetype = series,
           alpha = series)) +
  geom_line() +
  scale_color_manual(name = element_blank(), 
                     values = c("filtered" = "blue4", 
                                "smoothed" = "blue4",
                                "original" = "gray80",
                                "final" = "darkorange3")) +
  scale_linetype_manual(name = element_blank(), 
                        values = c("filtered" = "dotted", 
                                   "smoothed" = "solid", 
                                   "original" = "solid",
                                   "final" = "solid")) +
  scale_alpha_manual(name = element_blank(),
                     guide = 'none',
                     values = c("filtered" = 1, 
                                "smoothed" = 1, 
                                "original" = 0.4,
                                "final" = 1)) +
  labs(x = "", y = "", 
       title = "Transformation of topics series",
       caption = "smoothed = 30 day trailing moving average, filtered = biweight filter with bandwidth 1200, final = smoothed minus filtered series.") +
  scale_x_date(date_breaks = "5 years", date_labels = "%Y") +
  facet_wrap(~ topics, ncol = 2, scales = "free_y") +
  theme_minimal() +
  theme(legend.position = "top", 
        panel.grid.minor = element_blank(),
        plot.caption = element_text(size = 7))

```

Save plot as pdf
```{r}
ggsave(filename = "./topics_trafos.pdf", width = 20, height = 15, units = "cm")
```

## Analysis of the transformed series

### Plot all transformed time series

```{r}
stepsize <- 2
dat_trafo <- df_topics_trafo[ind_topics]
pdf(file="plot_all_trafo_topic.pdf", paper = "a4r", width = 10, height = 8)  
for (i in seq(1, ncol(dat_trafo), by = stepsize))
{
  matplot(df_topics_trafo$date, scale(dat_trafo[, i:(i+(stepsize-1))]), 
          type = "l", main = paste0("T", i-1, " to ", i+(stepsize-2)), # topics start counting at 0!!!! 
          col = c("cornflowerblue", "darkorange1", "darkorchid3"),
          ylab = "", xlab = "", lty = rep(1, stepsize))
  legend("topright", 
       legend = paste0("T", seq(i-1, i+(stepsize-2))), # topics start counting at 0!!!! 
       col = c("cornflowerblue", "darkorange1", "darkorchid3"),
       lty= rep(1, stepsize), cex= 1, box.lty = 0, y.intersp=2, bg="transparent")
}

dev.off()
```

### Principal components of (transformed) topics

Calculate eigenvalues and plot cumulative share of explained variance

```{r}
dat_pca <- dat_trafo 
eigvals_pca <- eigen(cor(dat_pca, use = "complete.obs"), only.values = T)
plot(seq(1, length(eigvals_pca$values)), 
     cumsum(eigvals_pca$values) / sum(eigvals_pca$values),
     xlab = "eigenvalue", ylab = "share of explained variance",
     main = "eigenvalue decomposition of dat_pca")
```
PCA based on EM algorithm following Stock and Watson (2002). Manually set number of factors to 10!
```{r}
pca <- f_emalg(scale(dat_pca), Nr_max = 10, Niter = 50, ic = "none",  print_iter = TRUE)
```
Plot PCs
```{r}
cols <- rep(c("cornflowerblue", 
              "darkorange1", 
              "darkorchid3", 
              "darkolivegreen4", 
              "brown"), times = 2)
ltys <- rep(c(1, 2), each = 5)
pdf(file="plot_pc_trafo.pdf", paper = "a4r", width = 10, height = 8)
matplot(df_topics_trafo$date, pca$f, 
        type = "l", lty = ltys, col = cols, 
        main = "First 10 principal components of transformed topics",
        ylab = "", xlab = "")
legend(as.Date("2004-01-01"), 2.0, 
       legend = paste0("PC", seq(1, 10)), 
       col = cols,
       lty= ltys, cex= 1, box.lty = 0, y.intersp=2, bg="transparent", ncol = 5)
dev.off()
```
Clean up workspace!
```{r}
rm(eigvals_pca, dat_pca, pca)
```


### Correlation analysis

#### Correlation between transformed topics

Calculate the correlation between the transformed topics
```{r}
cor_trafo <- cor(dat_trafo, use = "complete.obs")
cor_trafo_vec <- cor_trafo[lower.tri(cor_trafo)]
hist(cor_trafo_vec, breaks = 100)
```
#### Correlation with quarterly GDP growth

Aggregate transformed topics to quarterly frequency

```{r}
df_trafo <- cbind(df_topics_trafo[, 1:4], as.data.frame(dat_trafo))

df_trafo %>% 
  pivot_longer(cols = -c(date, year, quarter, month), 
               names_to = "topic", 
               values_to = "vals") %>%
  group_by(topic, year, quarter) %>%
  summarise(avg_vals = mean(vals, na.rm = T)) %>%
  pivot_wider(id_cols = c(year, quarter), 
              names_from = topic, 
              values_from = avg_vals) -> df_trafo_Q
```


```{r}
series <- "BBKRT.Q.DE.Y.A.AG1.CA010.A.I" 
df_gdp <- getSeries("BBKRT.Q.DE.Y.A.AG1.CA010.A.I") # calendar and seasonally adjusted GDP

# select last vintage and convert dates to column
df_gdp %>% 
  select(tail(names(.), 1)) %>%
  rownames_to_column(var = "date") %>%
  mutate(year = as.numeric(substr(date, 1, 4)), 
         month = as.numeric(substr(date, 6, 7)) + 1,  
         quarter = ceiling(month/3),
         date = make_date(year = year, month = month, day = 15) # middle of the quarter, e.g. 15.2. for Q1
         )-> df_gdp

# adjust name of series
names(df_gdp)[2] <- "gdp"

# calculate annualized quarterly growth rate
df_gdp$d_gdp <- c(NA, 400 * diff(log(df_gdp$gdp)))

# filter to match sample of transformed topics
df_gdp <- df_gdp[df_gdp$year >= 1991 & df_gdp$year <= 2018, ]
```


Calculate correlation between topics and GDP

```{r}
cor_topics_gdp <- cor(cbind(as.matrix(df_trafo_Q[, -c(1:2)]), df_gdp$d_gdp), use = "complete.obs")

# last row contains correlations of topics with GDP growth
cor_topics_gdp <- cor_topics_gdp[nrow(cor_topics_gdp), 1:(ncol(cor_topics_gdp) - 1)] 

# histogram
hist(cor_topics_gdp, breaks = 20)
             
# sort topics
as.data.frame(cor_topics_gdp) %>% 
  rownames_to_column(var = "topic") %>%
  mutate(abs_cor = abs(cor_topics_gdp)) %>%
  arrange(desc(abs_cor)) %>%
  head(10)
```
Plot 5 topics with the highest correlation 

```{r}
# sort by absolute correlation
top_topics <- sort(abs(cor_topics_gdp), decreasing = TRUE)
high_corr_topics <- names(top_topics[1:5])

#high_corr_topics <- c("T10", "T0", "T44", "T36", "T21") # automate!

cbind(data.frame(date = df_topics_trafo$date), scale(dat_trafo))  %>% 
  pivot_longer(cols = -date, names_to = "topic", values_to = "vals") %>%
  filter(topic %in% high_corr_topics) %>% 
  filter(date >= "1991-01-01" & date <= "2018-12-31") -> df_plot_topics

df_gdp %>% 
  mutate(d_gdp_stand = (d_gdp - mean(d_gdp, na.rm = T)) / sd(d_gdp, na.rm = T)) %>%
  filter(date >= "1991-01-01" & date <= "2018-12-31") -> df_plot_gdp

ggplot()+
  geom_line(mapping = aes(x = date, y = vals, group = topic, color = topic), 
            data = df_plot_topics, alpha = 0.5)+
  geom_point(mapping = aes(x = date, y = d_gdp_stand), 
             data = df_plot_gdp, size = 1, col = "black")+
  scale_color_jco(name = element_blank())+
  scale_x_date(date_breaks = "5 years", date_labels = "%Y")+
  labs(y = "standard deviation", x = "", title = "Transformed topics and economic activity",
       subtitles = "5 topics with the highest absolute correlation between annualized quarterly GDP growth",
       caption = "All series have been standardized. Note that the quarterly observations are placed in the middle of each quarter, e.g. February 15th for Q1.")+
  theme(legend.position = "bottom",
        plot.caption = element_text(size = 7))  
```

Save plot
```{r}
ggsave(filename = "plot_highcorr_topics_gdp.pdf", width = 20, height = 15, units = "cm")
```

